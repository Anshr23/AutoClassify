{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":89467,"status":"ok","timestamp":1753680817398,"user":{"displayName":"Aadi","userId":"17429767985240166296"},"user_tz":-330},"id":"QSF9MRBmIUun","outputId":"83be2c8f-8275-47cb-8cd8-4b29ef63bb72"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langdetect\n","  Downloading langdetect-1.0.9.tar.gz (981 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.7/981.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect) (1.17.0)\n","Building wheels for collected packages: langdetect\n","  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=f087be76e6670a93b6dd45eee2c656f29d9097b3d7a2e02e97a0f3849c8b73dc\n","  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n","Successfully built langdetect\n","Installing collected packages: langdetect\n","Successfully installed langdetect-1.0.9\n","Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n","Collecting sentence-transformers\n","  Downloading sentence_transformers-5.0.0-py3-none-any.whl.metadata (16 kB)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\n","Collecting transformers\n","  Downloading transformers-4.54.0-py3-none-any.whl.metadata (41 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.16.0)\n","Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.33.4)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.3.0)\n","Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n","Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n","  Downloading huggingface_hub-0.34.1-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n","Downloading sentence_transformers-5.0.0-py3-none-any.whl (470 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m470.2/470.2 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading transformers-4.54.0-py3-none-any.whl (11.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m124.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading huggingface_hub-0.34.1-py3-none-any.whl (558 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m558.8/558.8 kB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m125.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m103.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m110.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface-hub, nvidia-cusolver-cu12, transformers, sentence-transformers\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface-hub 0.33.4\n","    Uninstalling huggingface-hub-0.33.4:\n","      Successfully uninstalled huggingface-hub-0.33.4\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.53.3\n","    Uninstalling transformers-4.53.3:\n","      Successfully uninstalled transformers-4.53.3\n","  Attempting uninstall: sentence-transformers\n","    Found existing installation: sentence-transformers 4.1.0\n","    Uninstalling sentence-transformers-4.1.0:\n","      Successfully uninstalled sentence-transformers-4.1.0\n","Successfully installed huggingface-hub-0.34.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 sentence-transformers-5.0.0 transformers-4.54.0\n"]}],"source":["!pip install langdetect\n","!pip install --upgrade sentence-transformers transformers"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":2237,"status":"ok","timestamp":1753680873776,"user":{"displayName":"Aadi","userId":"17429767985240166296"},"user_tz":-330},"id":"c0d87UZ_44p7","outputId":"fd425757-936c-46dc-dbb5-aa4a0cd4634f","collapsed":true},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'AIzaSyAwLVHm49YsJu4PK6ilxc7MiwLxI6sBU7E'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}],"source":["from google.colab import userdata\n","userdata.get('GOOGLE_API_KEY')"]},{"cell_type":"markdown","source":["**UNSUPERVISED MODEL FOR SUPPLY**"],"metadata":{"id":"cRasd_M9gvvO"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"4yNKhhC7hI6d"},"outputs":[],"source":["import os\n","import pandas as pd\n","import re\n","import numpy as np\n","from collections import defaultdict\n","from nltk.corpus import stopwords as nltk_stopwords\n","import nltk\n","from langdetect import detect, DetectorFactory\n","from sentence_transformers import SentenceTransformer\n","import cudf\n","from cuml.cluster import KMeans\n","import google.generativeai as genai\n","from joblib import Parallel, delayed\n","import time\n","import torch\n","\n","# Set Gemini API key\n","os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyBHwfAgTs-RzC7uF4QzUSA30_HfMR9MwZQ\n","try:\n","    genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n","except KeyError:\n","    print(\" ERROR: GEMINI_API_KEY environment variable not set.\")\n","    print(\"Set it in PowerShell: $env:GEMINI_API_KEY = 'your_api_key_here'\")\n","    exit()\n","\n","DetectorFactory.seed = 0\n","\n","# Download NLTK stopwords\n","try:\n","    nltk.data.find('corpora/stopwords')\n","except LookupError:\n","    nltk.download('stopwords')\n","\n","# Define stopwords These words are considered less meaningful for categorization and are typically removed or ignored during text analysis.\n","UNIVERSAL_STOPWORDS = set(nltk_stopwords.words('english') + [\n","    'the', 'area', 'a', 'an', 'and', 'or', 'but', 'is', 'are', 'was', 'were', 'to', 'of', 'in', 'for', 'on', 'with', 'at', 'from', 'by', 'this', 'that', 'it', 'its', 'her', 'their', 'our',\n","    'what', 'where', 'how', 'why', 'who', 'whom', 'which', 'whether',\n","    'yesterday', 'today', 'tomorrow', 'morning', 'evening', 'night', 'day', 'days', 'hr', 'hrs', 'hour', 'hours', 'time', 'date', 'week', 'month', 'year', 'ago',\n","    'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'zero',\n","    'consumer', 'customer', 'number', 'no', 'code', 'id', 'location', 'address', 'phone', 'mobile', 'call', 'report', 'registered',\n","    'ok', 'yes', 'no', 'not', 'hi', 'hello', 'sir', 'madam', 'pls', 'please', 'regards', 'type', 'urban', 'complaint', 'detail', 'general',\n","    'kv', 'tf', 'na', 'service', 'request', 'feedback', 'query', 'regarding', 'about', 'given', 'areas', 'village'\n","])\n","\n","\n","\n","def clean_text(text: str) -> str:\n","    \"\"\"Removes extra whitespace and standardizes text (generic version).\"\"\"\n","    if pd.isna(text):\n","        return \"\"\n","    text = re.sub(r'\\s+', ' ', str(text).strip()).lower()\n","    return text\n","\n","\n","\n","def vectorized_time_categorization(df, remark_col, duration_col):\n","\n","    # Optimized time categorization using pandas str.extract.\n","\n","    print(\"     [Preprocessing] Vectorized time categorization...\")\n","\n","    # Applies regular expressions (hour_pattern, day_pattern) across the entire Series to extract numerical values associated with time units\n","    # (e.g., (\\d+\\.?\\d*) captures numbers, (?:hr|hrs|hour|hours|h) matches various hour terms non-capturingly).\n","    # This avoids slow row-by-row Python loops.\n","\n","    start_time = time.time()\n","    duration_series = df[duration_col] if duration_col in df.columns else df[remark_col]\n","    duration_series = duration_series.fillna(\"\").str.lower().apply(clean_text)\n","    hour_pattern = r'(\\d+\\.?\\d*)\\s*(?:hr|hrs|hour|hours|h)'\n","    day_pattern = r'(\\d+\\.?\\d*)\\s*(?:day|days)'\n","\n","    # Extract hours and days\n","    hours_extracted = duration_series.str.extract(hour_pattern)\n","    days_extracted = duration_series.str.extract(day_pattern)\n","\n","    # Initialize categories and hours\n","    categories = pd.Series([\"No Time Specified\"] * len(duration_series), index=df.index)\n","    extracted_hours = pd.Series([None] * len(duration_series), index=df.index, dtype=float)\n","\n","    # Process hours\n","    # Boolean Masking : for efficient conditional assignment of categories and extracted numerical hours\n","    hour_mask = hours_extracted[0].notna()\n","    hours = hours_extracted[0].astype(float)\n","    extracted_hours[hour_mask] = hours[hour_mask]\n","    categories[hour_mask & (hours < 4)] = \"Less than 4 hours\"\n","    categories[hour_mask & (hours >= 4) & (hours < 12)] = \"More than 4 hours\"\n","    categories[hour_mask & (hours >= 12) & (hours < 24)] = \"More than 12 hours\"\n","    categories[hour_mask & (hours >= 24)] = \"More than 24 hours\"\n","\n","    # Process days (where hours not already set)\n","    day_mask = days_extracted[0].notna() & hours_extracted[0].isna()\n","    days = days_extracted[0].astype(float)\n","    hours_from_days = days * 24\n","    extracted_hours[day_mask] = hours_from_days[day_mask]\n","    categories[day_mask & (hours_from_days < 4)] = \"Less than 4 hours\"\n","    categories[day_mask & (hours_from_days >= 4) & (hours_from_days < 12)] = \"More than 4 hours\"\n","    categories[day_mask & (hours_from_days >= 12) & (hours_from_days < 24)] = \"More than 12 hours\"\n","    categories[day_mask & (hours_from_days >= 24)] = \"More than 24 hours\"\n","\n","    print(f\"     [Preprocessing] Completed in {time.time() - start_time:.2f} seconds.\")\n","    return categories, extracted_hours\n","\n","\n","\n","def get_top_keywords(remarks: list[str], n_keywords: int = 10) -> list[str]:\n","\n","    \"\"\"\n","    Extracts top keywords using TF-IDF.\n","    A statistical measure that evaluates how relevant a word is to a document in a collection.\n","    It assigns a higher score to words that appear frequently in a specific document but rarely in the overall corpus\n","    (after removing common words like stopwords).\n","    \"\"\"\n","\n","    if not remarks or len(remarks) < 2:\n","        return []\n","    try:\n","        from sklearn.feature_extraction.text import TfidfVectorizer\n","        vectorizer = TfidfVectorizer(\n","            stop_words=list(UNIVERSAL_STOPWORDS), ngram_range=(1, 3), min_df=5, max_features=1000\n","        # ngram_range=(1, 3) : Considers unigrams (single words), bigrams (two-word phrases), and trigrams to capture more contextual meaning\n","        # min_df=5: Ignores terms that appear in fewer than 5 documents, helping to filter out rare or noisy terms\n","        # max_features=1000: Limits the total number of unique keywords considered, reducing dimensionality.\n","        )\n","        tfidf_matrix = vectorizer.fit_transform([r for r in remarks if r][:1000])\n","        feature_names = vectorizer.get_feature_names_out()\n","        scores = np.asarray(tfidf_matrix.sum(axis=0)).ravel()  # used as a proxy for the overall importance of each term in the collection\n","        top_indices = scores.argsort()[-n_keywords:][::-1]\n","        return [feature_names[i] for i in top_indices]\n","    except ValueError as e:\n","        print(f\"   [Warning] TF-IDF failed: {e}\")\n","        return []\n","\n","\n","\n","def get_genai_cluster_name(cluster_texts: list[str], top_keywords: list[str]) -> str:\n","    \"\"\"Generates a category name using Gemini API.\"\"\"\n","    print(\"    [Gen AI Naming] Sending prompt to Gemini model...\")\n","    if not cluster_texts:\n","        return \"Uncategorized Remarks\"\n","\n","    sample_size = min(20, len(cluster_texts))\n","    text_sample = \"\\n\".join([t[:100] for t in cluster_texts[:sample_size] if t])\n","\n","    prompt = f\"\"\"\n","    You are an expert at analyzing customer feedback in the energy sector. Provide a single, concise, professional category name for a group of similar remarks. The name must be 4-7 words, reflect the primary issue accurately, and avoid generic terms like 'Issues', 'Problems', or 'Reports' unless critical. Do not overlap with time-based categories (e.g., 'Less than 4 hours').\n","\n","    Top keywords: {', '.join(top_keywords[:5])}.\n","    Sample remarks:\n","    {text_sample}\n","\n","    Category name:\n","    \"\"\"\n","\n","    try:\n","        model = genai.GenerativeModel('gemini-2.5-flash')\n","        response = model.generate_content(prompt)\n","        name = response.text.strip().split(\"Category name:\")[-1].strip() if \"Category name:\" in response.text else response.text.strip()\n","        if not name or len(name.split()) < 4 or len(name.split()) > 7 or any(t.lower() in name.lower() for t in ['less', 'more', 'hours', 'time']):\n","            name = f\"{top_keywords[0].replace('_', ' ').title()} Incident Category\" if top_keywords else \"Uncategorized Remarks\"\n","        return name[:50].strip()\n","    except Exception as e:\n","        print(f\"    [Gen AI Naming] ERROR: API call failed. Falling back to keywords. Error: {e}\")\n","        return f\"{top_keywords[0].replace('_', ' ').title()} Incident Category\"[:50].strip() if top_keywords else \"Uncategorized Remarks\"\n","\n","\n","\n","def get_unique_name(base_name: str, existing_names: set, suffix_identifier: str = \"\") -> str:\n","    \"\"\"\n","    Generates a unique name.\n","    It iteratively appends alphabetical (A, B, C...) or alphanumeric (A1, A2...) suffixes to the base_name until a unique name is found that\n","    does not exist in the existing_names set. re.sub is used for initial cleaning of the base name\n","\n","    \"\"\"\n","    name = re.sub(r'[^a-zA-Z\\s]', '', base_name).strip()\n","    name = re.sub(r'\\s+', ' ', name).strip()\n","    if not name:\n","        name = \"Generic Category\"\n","    original_base = name\n","    alpha_suffix_idx = 0\n","    numeric_suffix_idx = 0\n","    while name.lower() in existing_names:\n","        if alpha_suffix_idx < 26:\n","            name = f\"{original_base} {chr(65 + alpha_suffix_idx)}\"\n","            alpha_suffix_idx += 1\n","        else:\n","            numeric_suffix_idx += 1\n","            alpha_suffix_idx_for_num = (alpha_suffix_idx - 26) % 26\n","            name = f\"{original_base} {chr(65 + alpha_suffix_idx_for_num)}{numeric_suffix_idx}\"\n","            alpha_suffix_idx += 1\n","    return name[:50].strip()\n","\n","\n","\n","def is_semantically_similar(name1: str, name2: str) -> bool:\n","    \"\"\"Uses Gemini to check if two column names are semantically similar.\"\"\"\n","    print(f\"   [Gen AI Merging] Checking similarity between '{name1}' and '{name2}'...\")\n","    prompt = f\"\"\"\n","    You are an expert at analyzing customer feedback in the energy sector. Determine if the following two category names are synonyms or convey the same meaning. Answer with a single word: \"YES\" or \"NO\".\n","\n","    Category 1: \"{name1}\"\n","    Category 2: \"{name2}\"\n","\n","    Recommendation:\n","    \"\"\"\n","    try:\n","        model = genai.GenerativeModel('gemini-2.5-flash')\n","        response = model.generate_content(prompt)\n","        recommendation = response.text.strip().split(\"Recommendation:\")[-1].strip() if \"Recommendation:\" in response.text else response.text.strip()\n","        return recommendation.lower() == \"yes\"\n","    except Exception as e:\n","        print(f\"    [Gen AI Merging] ERROR: API call failed. Error: {e}\")\n","        return False\n","\n","\n","\n","def merge_similar_columns(df: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"Merges non-time columns with semantically similar names\"\"\"\n","    print(\"\\n--- Merging similar non-time columns (Semantic Match) ---\")\n","    time_columns = [\n","        \"Less than 4 hours\",\n","        \"More than 4 hours\",\n","        \"More than 12 hours\",\n","        \"More than 24 hours\",\n","        \"No Time Specified\"\n","    ]\n","    columns_to_process = [col for col in df.columns if col not in time_columns]\n","    merged_mapping = {}\n","\n","    max_non_time_columns_target = 4\n","\n","    did_merge = True # loop allows for multiple rounds of merging until no more similar pairs are found or the target column count is reached.\n","    while did_merge and len(set(columns_to_process) - set(merged_mapping.keys())) > max_non_time_columns_target:\n","        did_merge = False\n","        current_active_cols = sorted([col for col in columns_to_process if col not in merged_mapping])\n","        # Sorting ensures a consistent order of comparison\n","\n","        for i in range(len(current_active_cols)):\n","            col1 = current_active_cols[i]\n","            if col1 in merged_mapping:                # This means col1 has already been chosen as a source in this iteration\n","                continue\n","\n","            for j in range(i + 1, len(current_active_cols)):\n","                col2 = current_active_cols[j]\n","                if col2 in merged_mapping:            # If col2 has already been chosen as a source in this iteration\n","                    continue\n","\n","                if is_semantically_similar(col1, col2):  # The AI call for similarity assessment.\n","                    current_unmerged_count = len(set(columns_to_process) - set(merged_mapping.keys()))\n","                    if current_unmerged_count > max_non_time_columns_target:\n","                        print(f\"    Merging '{col2}' into '{col1}' (Semantic Match)\")\n","                        merged_mapping[col2] = col1\n","                        did_merge = True\n","                        break                          # Found a merge, break inner loop to re-evaluate current_active_cols\n","            if did_merge:                              # If a merge happened in inner loop, break outer loop to restart while loop\n","                break\n","\n","    temp_df = df.copy()\n","    for source_col, target_col in merged_mapping.items():         # merged_mapping: A dictionary stores source_column_name: target_column_name pairs.\n","        if target_col not in temp_df.columns:\n","            temp_df[target_col] = np.nan\n","        temp_df.loc[:, target_col] = temp_df[target_col].fillna(temp_df[source_col])  # This is a key pandas operation, it takes all non-null\n","                                                                                      # values from source_col and fills corresponding NaN (missing)\n","                                                                                      # spots in target_col. This effectively moves remarks without\n","                                                                                      # overwriting existing data in the target.\n","        temp_df = temp_df.drop(columns=[source_col])               # Removes the source column after its data has been transferred.\n","\n","    final_columns = []\n","    for col in df.columns:\n","        if col in time_columns:\n","            final_columns.append(col)\n","        elif col not in merged_mapping.keys():                         # If it's a non-time column and not a source of a merge\n","            if col not in merged_mapping.values():                     # Ensure it's not a target that was just created\n","                final_columns.append(col)\n","\n","    for target_col in set(merged_mapping.values()):\n","        if target_col not in final_columns:\n","            final_columns.append(target_col)\n","\n","    final_column_order = sorted(final_columns, key=lambda x: (x not in time_columns, x))\n","    final_column_order = [col for col in final_column_order if col in temp_df.columns]\n","\n","    df_merged = temp_df[final_column_order]\n","    print(\"    Merging complete.\")\n","    return df_merged\n","\n","\n","\n","def load_excel_file(file_path: str, column: str) -> tuple[list[str], pd.DataFrame]:\n","    \"\"\"Loads remarks from an Excel file.\"\"\"\n","    print(f\"Loading data from '{file_path}'...\")\n","    start_time = time.time()\n","    try:\n","        df = pd.read_excel(file_path, usecols=[column, \"From When Issue Is Coming\"] if \"From When Issue Is Coming\" in pd.read_excel(file_path, nrows=1).columns else [column])\n","        print(f\"Loaded {len(df)} rows in {time.time() - start_time:.2f} seconds.\")\n","        remarks_list = [str(r) for r in df[column] if not pd.isna(r)]\n","        print(f\"Extracted {len(remarks_list)} valid remarks from column '{column}'.\")\n","        return remarks_list, df\n","    except FileNotFoundError as e:\n","        print(f\" ERROR: File '{file_path}' not found. {e}\")\n","        raise\n","    except Exception as e:\n","        print(f\" ERROR: Failed to load Excel file. {e}\")\n","        raise\n","\n","\n","\n","def save_results(df: pd.DataFrame, output_path: str):\n","    \"\"\"Saves results to an Excel file.\"\"\"\n","    print(f\"\\nSaving results to '{output_path}'...\")\n","    start_time = time.time()\n","    df.to_excel(output_path, index=False)        # saves the DataFrame to an Excel file without writing the pandas internal index as a column.\n","    print(f\"Saved successfully in {time.time() - start_time:.2f} seconds.\")\n","\n","\n","\n","def segregate_remarks_by_language(raw_remarks: list[str], min_text_for_detection: int = 10) -> tuple[list[tuple[int, str]], list[tuple[int, str]]]:\n","    \"\"\"Segregates remarks into English and other languages.\"\"\"\n","    print(f\"Starting language segregation for {len(raw_remarks)} remarks...\")\n","    start_time = time.time()\n","    def detect_lang(i, remark):\n","        cleaned_remark = clean_text(remark.lower())\n","        if len(cleaned_remark) < min_text_for_detection or not any(char.isalpha() for char in cleaned_remark):\n","            return i, remark, False\n","        try:\n","            return i, remark, detect(cleaned_remark) == 'en'\n","        except Exception:\n","            return i, remark, False\n","\n","    results = Parallel(n_jobs=-1)(delayed(detect_lang)(i, r) for i, r in enumerate(raw_remarks))\n","    english_remarks_with_indices = [(i, r) for i, r, is_en in results if is_en]\n","    other_remarks_with_indices = [(i, r) for i, r, is_en in results if not is_en]\n","    print(f\"Segregation complete in {time.time() - start_time:.2f} seconds. English: {len(english_remarks_with_indices)}, Other: {len(other_remarks_with_indices)}\")\n","    return english_remarks_with_indices, other_remarks_with_indices\n","\n","\n","\n","def cluster_remarks(remarks: list[str], n_clusters: int = 10, batch_size: int = 512) -> list[int]:\n","    \"\"\"\n","    Clusters remarks using sentence transformers and cuML KMeans.\n","    Loads a pre-trained Transformer model. This model converts full sentences into high-dimensional numerical vectors (embeddings).\n","    The key idea is that sentences with similar meanings will have embeddings that are numerically \"close\" to each other in this vector space.\n","    use an \"attention mechanism\" to weigh the importance of different words in a sentence relative to each other. This allows them to capture\n","    complex contextual relationships and produce high-quality semantic representations for entire sentences.\n","\n","    \"\"\"\n","    if not remarks:\n","        return []\n","    print(\"     [Clustering] Encoding remarks with sentence-transformers...\")\n","    start_time = time.time()\n","    model = SentenceTransformer('all-MiniLM-L6-v2', device='cuda')\n","    embeddings = []\n","    for i in range(0, len(remarks), batch_size):\n","        batch = remarks[i:i + batch_size]\n","        batch_embeddings = model.encode(batch, batch_size=batch_size, show_progress_bar=False, convert_to_numpy=True)\n","        embeddings.append(batch_embeddings)\n","    embeddings = np.vstack(embeddings)\n","    print(f\"     [Clustering] Encoding completed in {time.time() - start_time:.2f} seconds.\")\n","\n","\n","    \"\"\"\n","    K-Means is an unsupervised clustering algorithm that aims to partition n observations into k clusters. It works by iteratively assigning each\n","    data point to the closest cluster centroid and then re-calculating the centroids as the mean of the points in the cluster\n","\n","    \"\"\"\n","    print(\"     [Clustering] Performing KMeans clustering with cuML...\")\n","    start_time = time.time()\n","    gdf = cudf.DataFrame(embeddings)\n","    clustering = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n","    \"\"\"\n","    n_clusters: The desired number of clusters.\n","    random_state: Ensures the centroid initialization is reproducible.\n","    n_init=10: Runs the algorithm 10 times with different centroid initializations and picks the best result\n","    (minimizing inertia/sum of squared distances)\n","    \"\"\"\n","\n","    cluster_labels = clustering.fit_predict(gdf).to_numpy() # Performs the clustering on the GPU (gdf) and returns the cluster assignments for\n","                                                            # each remark as a NumPy array.\n","    print(f\"     [Clustering] Clustering completed in {time.time() - start_time:.2f} seconds.\")\n","    return cluster_labels\n","\n","\n","\n","def main():\n","    excel_file_path = \"./Supply.xlsx\"\n","    text_column_name = \"REMARKS\"\n","    duration_column_name = \"From When Issue Is Coming\"\n","    output_excel_path = \"./categorized_remarks_01.xlsx\"\n","    max_remark_clusters_limit = 8                    # This limits initial number of clusters for English remarks\n","    batch_size = 500\n","\n","    time_columns = [\n","        \"Less than 4 hours\",\n","        \"More than 4 hours\",\n","        \"More than 12 hours\",\n","        \"More than 24 hours\",\n","        \"No Time Specified\"\n","    ]\n","\n","    print(\"\\n--- Starting Remark Categorization Script ---\")\n","    start_time = time.time()\n","    try:\n","        raw_remarks_list, df = load_excel_file(excel_file_path, text_column_name)\n","\n","        print(f\"\\n--- Categorizing remarks ---\")\n","        time_categorized_remarks = {col: [] for col in time_columns}\n","        non_time_remarks_with_indices = []\n","\n","        categories, _ = vectorized_time_categorization(df, text_column_name, duration_column_name)\n","        # Handle cases where `categories` might not be directly iterable if df is empty etc.\n","        # Ensure `zip` handles potential length mismatch safely if remarks are cleaned/filtered.\n","        for i, (remark, category) in enumerate(zip(raw_remarks_list, categories)):\n","            if category != \"No Time Specified\":\n","                time_categorized_remarks[category].append((i, remark))\n","            else:\n","                non_time_remarks_with_indices.append((i, remark))\n","\n","        print(f\"Time-based categorization complete. Counts: { {k: len(v) for k, v in time_categorized_remarks.items()} }\")\n","        print(f\"Non-time remarks for further processing: {len(non_time_remarks_with_indices)}\")\n","\n","        print(\"\\n--- Segregating non-time remarks by language ---\")\n","        english_remarks_with_indices, other_remarks_with_indices = segregate_remarks_by_language(  # to check if non time remarks are english or not\n","            [r for _, r in non_time_remarks_with_indices]\n","        )\n","        # Re-map indices to original dataframe index\n","        english_remarks_with_indices_original = [(non_time_remarks_with_indices[local_idx][0], r) for local_idx, r in english_remarks_with_indices]\n","        other_remarks_with_indices_original = [(non_time_remarks_with_indices[local_idx][0], r) for local_idx, r in other_remarks_with_indices]\n","\n","\n","        print(f\"Non-time English remarks: {len(english_remarks_with_indices_original)}\")\n","        print(f\"Non-time other language remarks: {len(other_remarks_with_indices_original)}\")\n","\n","        # Initialize final_wide_data_columns with time-based categories\n","        final_wide_data_columns = {k: [r for _, r in v] for k, v in time_categorized_remarks.items()}\n","\n","        # original_indexed_cluster_labels is used to map back cluster labels to original df rows\n","        original_indexed_cluster_labels = np.full(len(raw_remarks_list), -2, dtype=int) # -2 for unclustered non-time\n","\n","        # final_column_name_map maps cluster IDs to generated category names\n","        final_column_name_map = {}\n","\n","        if english_remarks_with_indices_original:\n","            print(\"\\n--- Processing non-time English remarks for clustering ---\")\n","            english_remark_texts = [r for _, r in english_remarks_with_indices_original]\n","            english_remark_original_indices = [i for i, _ in english_remarks_with_indices_original]\n","\n","            # Determine number of clusters for KMeans, capping at max_remark_clusters_limit\n","            n_clusters_for_kmeans = min(max_remark_clusters_limit, len(english_remark_texts))\n","            if n_clusters_for_kmeans > 0: # Ensure we don't try to cluster with 0 clusters\n","                cluster_labels = cluster_remarks(english_remark_texts, n_clusters_for_kmeans, batch_size)\n","                print(f\"    [Clustering] Found {len(set(cluster_labels))} initial clusters.\")\n","\n","                # Apply cluster labels back to original remark indices\n","                for i, clustered_label in enumerate(cluster_labels):\n","                    original_indexed_cluster_labels[english_remark_original_indices[i]] = clustered_label\n","\n","                # Get unique cluster IDs for naming\n","                final_unique_clusters = sorted([c for c in set(cluster_labels) if c != -1]) # Exclude noise (-1 if DBSCAN was used)\n","                print(f\"    [Gen AI Naming] Naming {len(final_unique_clusters)} final clusters.\")\n","\n","                used_final_names = set(time_columns) # Keep track of names already in use (including time categories)\n","                for cluster_id in final_unique_clusters:\n","                    cluster_texts_original = [english_remark_texts[j] for j, label in enumerate(cluster_labels) if label == cluster_id]\n","                    top_keywords = get_top_keywords(cluster_texts_original)\n","                    print(f\"    [Keywords] Top keywords for cluster {cluster_id}: {', '.join(top_keywords)}\")\n","\n","                    proposed_final_name = get_genai_cluster_name(cluster_texts_original, top_keywords)\n","                    final_name = get_unique_name(proposed_final_name, used_final_names, str(cluster_id))\n","                    final_column_name_map[cluster_id] = final_name\n","                    used_final_names.add(final_name.lower())\n","                    print(f\"    Final Category Name: '{final_name}'\")\n","                    final_wide_data_columns[final_name] = cluster_texts_original\n","            else:\n","                print(\"    [Clustering] Not enough English remarks for clustering.\")\n","\n","        # Handle unclustered English remarks (if any)\n","        uncategorized_english_remarks = [(original_idx, r) for original_idx, r in english_remarks_with_indices_original if original_indexed_cluster_labels[original_idx] == -1] # Assuming -1 for noise/unclustered\n","        if uncategorized_remarks := [r for _, r in uncategorized_english_remarks]:\n","            col_name = get_unique_name(\"Uncategorized English Remarks\", set(final_wide_data_columns.keys()).union(set(final_column_name_map.values())), \"uncat_en\")\n","            final_wide_data_columns[col_name] = uncategorized_remarks\n","            print(f\"\\nAdded column: '{col_name}' for {len(uncategorized_remarks)} remarks.\")\n","\n","        # Handle other language remarks\n","        if other_remarks := [r for _, r in other_remarks_with_indices_original]:\n","            col_name = get_unique_name(\"Other Language Remarks\", set(final_wide_data_columns.keys()).union(set(final_column_name_map.values())), \"other_lang\")\n","            final_wide_data_columns[col_name] = other_remarks\n","            print(f\"Added column: '{col_name}' for {len(other_remarks)} remarks.\")\n","\n","        # Create wide format DataFrame\n","        max_rows = max(len(remarks) for remarks in final_wide_data_columns.values()) if final_wide_data_columns else 0\n","        df_results_wide = pd.DataFrame({\n","            col: remarks + [\"\"] * (max_rows - len(remarks))\n","            for col, remarks in final_wide_data_columns.items()\n","        })\n","\n","        print(\"\\n--- Merging non-time columns ---\")\n","        non_time_columns_pre_merge = [col for col in df_results_wide.columns if col not in time_columns]\n","        if len(non_time_columns_pre_merge) > 4: # Only attempt merge if there are more than 4 non-time columns\n","            df_results_wide = merge_similar_columns(df_results_wide)\n","        else:\n","            print(f\"Skipping semantic merging. Number of non-time columns ({len(non_time_columns_pre_merge)}) is already at or below the target of 4.\")\n","\n","\n","        print(f\"\\nCategorization complete. Column counts: { {k: len([x for x in df_results_wide[k] if x]) for k in df_results_wide.columns} }\")\n","        print(\"\\n--- Validating Categories ---\")\n","        for col in df_results_wide.columns:\n","            print(f\"Category '{col}' ({len([x for x in df_results_wide[col] if x])} remarks):\")\n","            for r in df_results_wide[col][:min(5, len(df_results_wide[col]))]:\n","                if r:\n","                    print(f\"   - {r[:100]}...\")\n","\n","        save_results(df_results_wide, output_excel_path)\n","        print(\"\\n--- Sample Results ---\")\n","        print(df_results_wide.head())\n","        print(f\"\\n--- Script completed in {time.time() - start_time:.2f} seconds ---\")\n","\n","    except FileNotFoundError as fnfe:\n","        print(f\"\\nERROR: File not found. Please check 'excel_file_path'. Details: {fnfe}\")\n","        exit(1)\n","    except KeyError as ke:\n","        print(f\"\\nERROR: Column not found. Please check 'text_column_name' or 'duration_column_name'. Details: {ke}\")\n","        exit(1)\n","    except Exception as e:\n","        print(f\"\\nAn unexpected error occurred: {e}\")\n","        import traceback\n","        traceback.print_exc()\n","        exit(1)\n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import re\n","import numpy as np\n","from collections import defaultdict\n","from nltk.corpus import stopwords as nltk_stopwords\n","import nltk\n","from langdetect import detect, DetectorFactory\n","from sentence_transformers import SentenceTransformer\n","import cudf\n","from cuml.cluster import KMeans\n","import google.generativeai as genai\n","from joblib import Parallel, delayed\n","import time\n","import torch\n","\n","os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyBHwfAgTs-RzC7uF4QzUSA30_HfMR9MwZQ\"\n","try:\n","    genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n","except KeyError:\n","    print(\" ERROR: GEMINI_API_KEY environment variable not set.\")\n","    print(\"Set it in PowerShell: $env:GEMINI_API_KEY = 'your_api_key_here'\")\n","    exit()\n","\n","DetectorFactory.seed = 0\n","\n","try:\n","    nltk.data.find('corpora/stopwords')\n","except LookupError:\n","    nltk.download('stopwords')\n","\n","UNIVERSAL_STOPWORDS = set(nltk_stopwords.words('english') + [\n","    'the', 'area', 'a', 'an', 'and', 'or', 'but', 'is', 'are', 'was', 'were', 'to', 'of', 'in', 'for', 'on', 'with', 'at', 'from', 'by', 'this', 'that', 'it', 'its', 'her', 'their', 'our',\n","    'what', 'where', 'how', 'why', 'who', 'whom', 'which', 'whether',\n","    'yesterday', 'today', 'tomorrow', 'morning', 'evening', 'night', 'day', 'days', 'hr', 'hrs', 'hour', 'hours', 'time', 'date', 'week', 'month', 'year', 'ago',\n","    'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'zero',\n","    'consumer', 'customer', 'number', 'no', 'code', 'id', 'location', 'address', 'phone', 'mobile', 'call', 'report', 'registered',\n","    'ok', 'yes', 'no', 'not', 'hi', 'hello', 'sir', 'madam', 'pls', 'please', 'regards', 'type', 'urban', 'complaint', 'detail', 'general',\n","    'kv', 'tf', 'na', 'service', 'request', 'feedback', 'query', 'regarding', 'about', 'given', 'areas', 'village'\n","])\n","\n","\n","\n","def clean_text(text: str) -> str:\n","    if pd.isna(text):\n","        return \"\"\n","    text = re.sub(r'\\s+', ' ', str(text).strip()).lower()\n","    return text\n","\n","\n","\n","def vectorized_time_categorization(df, remark_col, duration_col):\n","\n","    print(\"      [Preprocessing] Vectorized time categorization...\")\n","\n","    start_time = time.time()\n","    duration_series = df[duration_col] if duration_col in df.columns else df[remark_col]\n","    duration_series = duration_series.fillna(\"\").str.lower().apply(clean_text)\n","    hour_pattern = r'(\\d+\\.?\\d*)\\s*(?:hr|hrs|hour|hours|h)'\n","    day_pattern = r'(\\d+\\.?\\d*)\\s*(?:day|days)'\n","\n","    hours_extracted = duration_series.str.extract(hour_pattern)\n","    days_extracted = duration_series.str.extract(day_pattern)\n","\n","    categories = pd.Series([\"No Time Specified\"] * len(duration_series), index=df.index)\n","    extracted_hours = pd.Series([None] * len(duration_series), index=df.index, dtype=float)\n","\n","    hour_mask = hours_extracted[0].notna()\n","    hours = hours_extracted[0].astype(float)\n","    extracted_hours[hour_mask] = hours[hour_mask]\n","    categories[hour_mask & (hours < 4)] = \"Less than 4 hours\"\n","    categories[hour_mask & (hours >= 4) & (hours < 12)] = \"More than 4 hours\"\n","    categories[hour_mask & (hours >= 12) & (hours < 24)] = \"More than 12 hours\"\n","    categories[hour_mask & (hours >= 24)] = \"More than 24 hours\"\n","\n","    day_mask = days_extracted[0].notna() & hours_extracted[0].isna()\n","    days = days_extracted[0].astype(float)\n","    hours_from_days = days * 24\n","    extracted_hours[day_mask] = hours_from_days[day_mask]\n","    categories[day_mask & (hours_from_days < 4)] = \"Less than 4 hours\"\n","    categories[day_mask & (hours_from_days >= 4) & (hours_from_days < 12)] = \"More than 4 hours\"\n","    categories[day_mask & (hours_from_days >= 12) & (hours_from_days < 24)] = \"More than 12 hours\"\n","    categories[day_mask & (hours_from_days >= 24)] = \"More than 24 hours\"\n","\n","    print(f\"      [Preprocessing] Completed in {time.time() - start_time:.2f} seconds.\")\n","    return categories, extracted_hours\n","\n","\n","\n","def get_top_keywords(remarks: list[str], n_keywords: int = 10) -> list[str]:\n","\n","    if not remarks or len(remarks) < 2:\n","        return []\n","    try:\n","        from sklearn.feature_extraction.text import TfidfVectorizer\n","        vectorizer = TfidfVectorizer(\n","            stop_words=list(UNIVERSAL_STOPWORDS), ngram_range=(1, 3), min_df=5, max_features=1000\n","        )\n","        tfidf_matrix = vectorizer.fit_transform([r for r in remarks if r][:1000])\n","        feature_names = vectorizer.get_feature_names_out()\n","        scores = np.asarray(tfidf_matrix.sum(axis=0)).ravel()\n","        top_indices = scores.argsort()[-n_keywords:][::-1]\n","        return [feature_names[i] for i in top_indices]\n","    except ValueError as e:\n","        print(f\"   [Warning] TF-IDF failed: {e}\")\n","        return []\n","\n","\n","\n","def get_genai_cluster_name(cluster_texts: list[str], top_keywords: list[str]) -> str:\n","    print(\"      [Gen AI Naming] Sending prompt to Gemini model...\")\n","    if not cluster_texts:\n","        return \"Uncategorized Remarks\"\n","\n","    sample_size = min(20, len(cluster_texts))\n","    text_sample = \"\\n\".join([t[:100] for t in cluster_texts[:sample_size] if t])\n","\n","    prompt = f\"\"\"\n","    You are an expert at analyzing customer feedback in the energy sector. Provide a single, concise, professional category name for a group of similar remarks. The name must be 4-7 words, reflect the primary issue accurately, and avoid generic terms like 'Issues', 'Problems', or 'Reports' unless critical. Do not overlap with time-based categories (e.g., 'Less than 4 hours').\n","\n","    Top keywords: {', '.join(top_keywords[:5])}.\n","    Sample remarks:\n","    {text_sample}\n","\n","    Category name:\n","    \"\"\"\n","\n","    try:\n","        model = genai.GenerativeModel('gemini-2.5-flash')\n","        response = model.generate_content(prompt)\n","        name = response.text.strip().split(\"Category name:\")[-1].strip() if \"Category name:\" in response.text else response.text.strip()\n","        if not name or len(name.split()) < 4 or len(name.split()) > 7 or any(t.lower() in name.lower() for t in ['less', 'more', 'hours', 'time']):\n","            name = f\"{top_keywords[0].replace('_', ' ').title()} Incident Category\" if top_keywords else \"Uncategorized Remarks\"\n","        return name[:50].strip()\n","    except Exception as e:\n","        print(f\"      [Gen AI Naming] ERROR: API call failed. Falling back to keywords. Error: {e}\")\n","        return f\"{top_keywords[0].replace('_', ' ').title()} Incident Category\"[:50].strip() if top_keywords else \"Uncategorized Remarks\"\n","\n","\n","\n","def get_unique_name(base_name: str, existing_names: set, suffix_identifier: str = \"\") -> str:\n","    name = re.sub(r'[^a-zA-Z\\s]', '', base_name).strip()\n","    name = re.sub(r'\\s+', ' ', name).strip()\n","    if not name:\n","        name = \"Generic Category\"\n","    original_base = name\n","    alpha_suffix_idx = 0\n","    numeric_suffix_idx = 0\n","    while name.lower() in existing_names:\n","        if alpha_suffix_idx < 26:\n","            name = f\"{original_base} {chr(65 + alpha_suffix_idx)}\"\n","            alpha_suffix_idx += 1\n","        else:\n","            numeric_suffix_idx += 1\n","            alpha_suffix_idx_for_num = (alpha_suffix_idx - 26) % 26\n","            name = f\"{original_base} {chr(65 + alpha_suffix_idx_for_num)}{numeric_suffix_idx}\"\n","            alpha_suffix_idx += 1\n","    return name[:50].strip()\n","\n","\n","\n","def is_semantically_similar(name1: str, name2: str) -> bool:\n","    print(f\"    [Gen AI Merging] Checking similarity between '{name1}' and '{name2}'...\")\n","    prompt = f\"\"\"\n","    You are an expert at analyzing customer feedback in the energy sector. Determine if the following two category names are synonyms or convey the same meaning. Answer with a single word: \"YES\" or \"NO\".\n","\n","    Category 1: \"{name1}\"\n","    Category 2: \"{name2}\"\n","\n","    Recommendation:\n","    \"\"\"\n","    try:\n","        model = genai.GenerativeModel('gemini-2.5-flash')\n","        response = model.generate_content(prompt)\n","        recommendation = response.text.strip().split(\"Recommendation:\")[-1].strip() if \"Recommendation:\" in response.text else response.text.strip()\n","        return recommendation.lower() == \"yes\"\n","    except Exception as e:\n","        print(f\"      [Gen AI Merging] ERROR: API call failed. Error: {e}\")\n","        return False\n","\n","\n","\n","def merge_similar_columns(df: pd.DataFrame, max_target_columns: int) -> pd.DataFrame:\n","    print(\"\\n--- Merging similar columns (Semantic Match) ---\")\n","    columns_to_process = list(df.columns)\n","    merged_mapping = {}\n","\n","    did_merge = True\n","    while did_merge and len(set(columns_to_process) - set(merged_mapping.keys())) > max_target_columns:\n","        did_merge = False\n","        current_active_cols = sorted([col for col in columns_to_process if col not in merged_mapping])\n","\n","        for i in range(len(current_active_cols)):\n","            col1 = current_active_cols[i]\n","            if col1 in merged_mapping:\n","                continue\n","\n","            for j in range(i + 1, len(current_active_cols)):\n","                col2 = current_active_cols[j]\n","                if col2 in merged_mapping:\n","                    continue\n","\n","                if is_semantically_similar(col1, col2):\n","                    current_unmerged_count = len(set(columns_to_process) - set(merged_mapping.keys()))\n","                    if current_unmerged_count > max_target_columns:\n","                        print(f\"      Merging '{col2}' into '{col1}' (Semantic Match)\")\n","                        merged_mapping[col2] = col1\n","                        did_merge = True\n","                        break\n","            if did_merge:\n","                break\n","\n","    temp_df = df.copy()\n","    for source_col, target_col in merged_mapping.items():\n","        if target_col not in temp_df.columns:\n","            temp_df[target_col] = np.nan\n","        temp_df.loc[:, target_col] = temp_df[target_col].fillna(temp_df[source_col])\n","        temp_df = temp_df.drop(columns=[source_col])\n","\n","    final_columns = []\n","    for col in df.columns:\n","        if col not in merged_mapping.keys():\n","            if col not in merged_mapping.values():\n","                final_columns.append(col)\n","\n","    for target_col in set(merged_mapping.values()):\n","        if target_col not in final_columns:\n","            final_columns.append(target_col)\n","\n","    final_column_order = sorted(final_columns)\n","    final_column_order = [col for col in final_column_order if col in temp_df.columns]\n","\n","    df_merged = temp_df[final_column_order]\n","    print(\"      Merging complete.\")\n","    return df_merged\n","\n","\n","\n","def load_excel_file(file_path: str, column: str) -> tuple[list[str], pd.DataFrame]:\n","    print(f\"Loading data from '{file_path}'...\")\n","    start_time = time.time()\n","    try:\n","        df = pd.read_excel(file_path, usecols=[column])\n","        print(f\"Loaded {len(df)} rows in {time.time() - start_time:.2f} seconds.\")\n","        remarks_list = [str(r) for r in df[column] if not pd.isna(r)]\n","        print(f\"Extracted {len(remarks_list)} valid remarks from column '{column}'.\")\n","        return remarks_list, df\n","    except FileNotFoundError as e:\n","        print(f\" ERROR: File '{file_path}' not found. {e}\")\n","        raise\n","    except Exception as e:\n","        print(f\" ERROR: Failed to load Excel file. {e}\")\n","        raise\n","\n","\n","\n","def save_results(df: pd.DataFrame, output_path: str):\n","    print(f\"\\nSaving results to '{output_path}'...\")\n","    start_time = time.time()\n","    df.to_excel(output_path, index=False)\n","    print(f\"Saved successfully in {time.time() - start_time:.2f} seconds.\")\n","\n","\n","\n","def segregate_remarks_by_language(raw_remarks: list[str], min_text_for_detection: int = 10) -> tuple[list[tuple[int, str]], list[tuple[int, str]]]:\n","    print(f\"Starting language segregation for {len(raw_remarks)} remarks...\")\n","    start_time = time.time()\n","    def detect_lang(i, remark):\n","        cleaned_remark = clean_text(remark.lower())\n","        if len(cleaned_remark) < min_text_for_detection or not any(char.isalpha() for char in cleaned_remark):\n","            return i, remark, False\n","        try:\n","            return i, remark, detect(cleaned_remark) == 'en'\n","        except Exception:\n","            return i, remark, False\n","\n","    results = Parallel(n_jobs=-1)(delayed(detect_lang)(i, r) for i, r in enumerate(raw_remarks))\n","    english_remarks_with_indices = [(i, r) for i, r, is_en in results if is_en]\n","    other_remarks_with_indices = [(i, r) for i, r, is_en in results if not is_en]\n","    print(f\"Segregation complete in {time.time() - start_time:.2f} seconds. English: {len(english_remarks_with_indices)}, Other: {len(other_remarks_with_indices)}\")\n","    return english_remarks_with_indices, other_remarks_with_indices\n","\n","\n","\n","def cluster_remarks(remarks: list[str], n_clusters: int = 10, batch_size: int = 512) -> list[int]:\n","    if not remarks:\n","        return []\n","    print(\"      [Clustering] Encoding remarks with sentence-transformers...\")\n","    start_time = time.time()\n","    model = SentenceTransformer('all-MiniLM-L6-v2', device='cuda')\n","    embeddings = []\n","    for i in range(0, len(remarks), batch_size):\n","        batch = remarks[i:i + batch_size]\n","        batch_embeddings = model.encode(batch, batch_size=batch_size, show_progress_bar=False, convert_to_numpy=True)\n","        embeddings.append(batch_embeddings)\n","    embeddings = np.vstack(embeddings)\n","    print(f\"      [Clustering] Encoding completed in {time.time() - start_time:.2f} seconds.\")\n","\n","\n","    print(\"      [Clustering] Performing KMeans clustering with cuML...\")\n","    start_time = time.time()\n","    gdf = cudf.DataFrame(embeddings)\n","    clustering = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n","\n","    cluster_labels = clustering.fit_predict(gdf).to_numpy()\n","    print(f\"      [Clustering] Clustering completed in {time.time() - start_time:.2f} seconds.\")\n","    return cluster_labels\n","\n","\n","\n","def main():\n","    excel_file_path = \"./Meter.xlsx\"\n","    text_column_name = \"REMARKS\"\n","    output_excel_path = \"./categorized_remarks_03.xlsx\"\n","    max_remark_clusters_target = 10\n","    batch_size = 500\n","\n","    print(\"\\n--- Starting Remark Categorization Script (No Time Categories) ---\")\n","    start_time = time.time()\n","    try:\n","        raw_remarks_list, df = load_excel_file(excel_file_path, text_column_name)\n","\n","        print(\"\\n--- Segregating remarks by language ---\")\n","        english_remarks_with_indices, other_remarks_with_indices = segregate_remarks_by_language(\n","            raw_remarks_list\n","        )\n","\n","        print(f\"English remarks for clustering: {len(english_remarks_with_indices)}\")\n","        print(f\"Other language remarks: {len(other_remarks_with_indices)}\")\n","\n","        final_wide_data_columns = {}\n","\n","        original_indexed_cluster_labels = np.full(len(raw_remarks_list), -2, dtype=int)\n","\n","        final_column_name_map = {}\n","\n","        if english_remarks_with_indices:\n","            print(\"\\n--- Processing English remarks for clustering ---\")\n","            english_remark_texts = [r for _, r in english_remarks_with_indices]\n","            english_remark_original_indices = [i for i, _ in english_remarks_with_indices]\n","\n","            n_clusters_initial = min(len(english_remark_texts), 20)\n","\n","            if n_clusters_initial > 0:\n","                cluster_labels = cluster_remarks(english_remark_texts, n_clusters_initial, batch_size)\n","                print(f\"      [Clustering] Found {len(set(cluster_labels))} initial clusters.\")\n","\n","                for i, clustered_label in enumerate(cluster_labels):\n","                    original_indexed_cluster_labels[english_remark_original_indices[i]] = clustered_label\n","\n","                initial_unique_clusters = sorted([c for c in set(cluster_labels) if c != -1])\n","                print(f\"      [Gen AI Naming] Naming {len(initial_unique_clusters)} initial clusters.\")\n","\n","                temp_cluster_data = defaultdict(list)\n","                for i, r in english_remarks_with_indices:\n","                    cluster_id = original_indexed_cluster_labels[i]\n","                    if cluster_id != -1:\n","                        temp_cluster_data[cluster_id].append(r)\n","\n","                used_initial_names = set()\n","                initial_named_clusters = {}\n","                for cluster_id in initial_unique_clusters:\n","                    cluster_texts_original = temp_cluster_data[cluster_id]\n","                    if cluster_texts_original:\n","                        top_keywords = get_top_keywords(cluster_texts_original)\n","                        print(f\"      [Keywords] Top keywords for cluster {cluster_id}: {', '.join(top_keywords)}\")\n","\n","                        proposed_name = get_genai_cluster_name(cluster_texts_original, top_keywords)\n","                        unique_initial_name = get_unique_name(proposed_name, used_initial_names)\n","                        initial_named_clusters[unique_initial_name] = cluster_texts_original\n","                        used_initial_names.add(unique_initial_name.lower())\n","                        print(f\"      Initial Category Name for cluster {cluster_id}: '{unique_initial_name}'\")\n","            else:\n","                print(\"      [Clustering] Not enough English remarks for clustering.\")\n","                initial_named_clusters = {}\n","        else:\n","            initial_named_clusters = {}\n","\n","        if initial_named_clusters:\n","            max_len = max(len(v) for v in initial_named_clusters.values())\n","            df_for_merging = pd.DataFrame({\n","                name: data + [''] * (max_len - len(data))\n","                for name, data in initial_named_clusters.items()\n","            })\n","        else:\n","            df_for_merging = pd.DataFrame()\n","\n","\n","        if not df_for_merging.empty and len(df_for_merging.columns) > max_remark_clusters_target:\n","            df_merged_clusters = merge_similar_columns(df_for_merging, max_remark_clusters_target)\n","            final_wide_data_columns.update({col: list(df_merged_clusters[col].dropna()) for col in df_merged_clusters.columns})\n","        elif not df_for_merging.empty:\n","            print(f\"Skipping semantic merging. Number of clusters ({len(df_for_merging.columns)}) is already at or below the target of {max_remark_clusters_target}.\")\n","            final_wide_data_columns.update({col: list(df_for_merging[col].dropna()) for col in df_for_merging.columns})\n","        else:\n","            print(\"No English remarks to form initial clusters.\")\n","\n","\n","        all_categorized_english_remarks_texts = set()\n","        for col in final_wide_data_columns:\n","            all_categorized_english_remarks_texts.update(final_wide_data_columns[col])\n","\n","        uncategorized_english_remarks = [(original_idx, r) for original_idx, r in english_remarks_with_indices if r not in all_categorized_english_remarks_texts]\n","\n","        if uncategorized_remarks_texts := [r for _, r in uncategorized_english_remarks]:\n","            col_name = get_unique_name(\"Uncategorized English Remarks\", set(final_wide_data_columns.keys()), \"uncat_en\")\n","            final_wide_data_columns[col_name] = uncategorized_remarks_texts\n","            print(f\"\\nAdded column: '{col_name}' for {len(uncategorized_remarks_texts)} remarks.\")\n","\n","\n","        if other_remarks := [r for _, r in other_remarks_with_indices]:\n","            col_name = get_unique_name(\"Other Language Remarks\", set(final_wide_data_columns.keys()), \"other_lang\")\n","            final_wide_data_columns[col_name] = other_remarks\n","            print(f\"Added column: '{col_name}' for {len(other_remarks)} remarks.\")\n","\n","\n","        max_rows = max(len(remarks) for remarks in final_wide_data_columns.values()) if final_wide_data_columns else 0\n","        df_results_wide = pd.DataFrame({\n","            col: remarks + [\"\"] * (max_rows - len(remarks))\n","            for col, remarks in final_wide_data_columns.items()\n","        })\n","\n","\n","        print(f\"\\nCategorization complete. Column counts: { {k: len([x for x in df_results_wide[k] if x]) for k in df_results_wide.columns} }\")\n","        print(\"\\n--- Validating Categories ---\")\n","        for col in df_results_wide.columns:\n","            print(f\"Category '{col}' ({len([x for x in df_results_wide[col] if x])} remarks):\")\n","            for r in df_results_wide[col][:min(5, len(df_results_wide[col]))]:\n","                if r:\n","                    print(f\"    - {r[:100]}...\")\n","\n","        save_results(df_results_wide, output_excel_path)\n","        print(\"\\n--- Sample Results ---\")\n","        print(df_results_wide.head())\n","        print(f\"\\n--- Script completed in {time.time() - start_time:.2f} seconds ---\")\n","\n","    except FileNotFoundError as fnfe:\n","        print(f\"\\nERROR: File not found. Please check 'excel_file_path'. Details: {fnfe}\")\n","        exit(1)\n","    except KeyError as ke:\n","        print(f\"\\nERROR: Column not found. Please check 'text_column_name'. Details: {ke}\")\n","        exit(1)\n","    except Exception as e:\n","        print(f\"\\nAn unexpected error occurred: {e}\")\n","        import traceback\n","        traceback.print_exc()\n","        exit(1)\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"qRB7_gh7ix9S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import re\n","from nltk.corpus import stopwords as nltk_stopwords\n","import nltk\n","\n","# Ensure NLTK stopwords are downloaded\n","try:\n","    nltk.data.find('corpora/stopwords')\n","except LookupError:\n","    nltk.download('stopwords')\n","\n","# Define stopwords (from your original code, ensure consistency)\n","UNIVERSAL_STOPWORDS = set(nltk_stopwords.words('english') + [\n","    'the', 'area', 'a', 'an', 'and', 'or', 'but', 'is', 'are', 'was', 'were', 'to', 'of', 'in', 'for', 'on', 'with', 'at', 'from', 'by', 'this', 'that', 'it', 'its', 'her', 'their', 'our',\n","    'what', 'where', 'how', 'why', 'who', 'whom', 'which', 'whether',\n","    'yesterday', 'today', 'tomorrow', 'morning', 'evening', 'night', 'day', 'days', 'hr', 'hrs', 'hour', 'hours', 'time', 'date', 'week', 'month', 'year', 'ago',\n","    'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'zero',\n","    'consumer', 'customer', 'number', 'no', 'code', 'id', 'location', 'address', 'phone', 'mobile', 'call', 'report', 'registered',\n","    'ok', 'yes', 'no', 'not', 'hi', 'hello', 'sir', 'madam', 'pls', 'please', 'regards', 'type', 'urban', 'complaint', 'detail', 'general',\n","    'kv', 'tf', 'na', 'service', 'request', 'feedback', 'query', 'regarding', 'about', 'given', 'areas', 'village'\n","])\n","\n","def clean_text(text: str) -> str:\n","    \"\"\"Removes extra whitespace and standardizes text (generic version).\"\"\"\n","    if pd.isna(text):\n","        return \"\"\n","    text = re.sub(r'\\s+', ' ', str(text).strip()).lower()\n","    return text\n","\n","# --- Step 1.1: Load the Excel file ---\n","excel_file_path = \"./DATA.xlsx\"\n","\n","try:\n","    df_raw_labeled = pd.read_excel(excel_file_path, header=0)\n","    print(f\"Successfully loaded '{excel_file_path}'. Shape: {df_raw_labeled.shape}\")\n","    print(\"\\nFirst 5 rows of the raw data (DATA.xlsx content):\")\n","    print(df_raw_labeled.head())\n","    print(\"\\nColumns (Categories) identified from the raw data:\")\n","    print(df_raw_labeled.columns.tolist())\n","\n","    \"\"\" for supply\n","    desired_category_labels = [\n","        \"Less than 4 hours\",\n","        \"More than 12 hours\",\n","        \"More than 24 hours\",\n","        \"More than 4 hours\",\n","        \"Consumer Power Supply Failures\",\n","        \"Failed Pole Incident Category\",\n","        \"Other Language Remarks\",\n","        \"Partial Phase Supply Failure\",\n","        \"Transformer Damage Causing Outages\"\n","    ]\n","    \"\"\"\n","\n","    desired_category_labels = [\n","        \"Bill Accuracy and Discrepancies\",\n","        \"Bill Content and Delivery Discrepancies\",\n","        \"Bill Hold Preventing Online Payments\",\n","        \"Billing Discrepancies Due to Meter Readings\",\n","        \"Customer Billing Not Received or Available\",\n","        \"Customer Reported Billing Inaccuracie\",\n","        \"Other Language Remarks\",\n","        \"Domestic Connection Billing Discrepancies\",\n","        \"Domestic Meter Reading Collection Failure\"\n","        \"Electricity Bill Discrepancies and Solar Units\"\n","        \"Rectifying Account and Billing Discrepancies\"\n","        \"Unacknowledged Customer Payments and Billing\"\n","    ]\n","\n","    loaded_to_label_map = {}\n","    seen_labels = {} # To handle pandas' .1, .2 suffixes\n","\n","    for col in df_raw_labeled.columns:\n","        # Normalize column name for comparison\n","        normalized_col = col.split('.')[0] # Remove .1, .2 suffixes if present\n","\n","        if normalized_col in desired_category_labels:\n","            if normalized_col in seen_labels:\n","                loaded_to_label_map[col] = normalized_col\n","            else:\n","                loaded_to_label_map[col] = col # No suffix, direct map\n","                seen_labels[normalized_col] = True\n","        else:\n","            print(f\"Warning: Column '{col}' from Excel file is not in the list of desired categories. It will be ignored for training data. If this is a category, please add it to 'desired_category_labels'.\")\n","\n","    active_category_columns_in_df = list(loaded_to_label_map.keys())\n","\n","    print(f\"\\nIdentified {len(set(loaded_to_label_map.values()))} Unique Category Labels for Training:\")\n","    print(list(set(loaded_to_label_map.values())))\n","    print(f\"\\nColumns from Excel file that will be processed (including any pandas-generated suffixes):\")\n","    print(active_category_columns_in_df)\n","\n","    # --- Step 1.3: Transform the wide format into a long format (remark_cleaned, category) ---\n","    labeled_data_for_training = []\n","\n","    for category_col_in_df in active_category_columns_in_df:\n","        # Get the standardized category label for this column\n","        standard_category_label = loaded_to_label_map[category_col_in_df]\n","\n","        # Iterate through each non-empty remark in that column\n","        for remark_entry in df_raw_labeled[category_col_in_df].dropna():\n","            cleaned_remark = clean_text(str(remark_entry)) # Ensure it's a string before cleaning\n","\n","            if cleaned_remark: # Only add if the cleaned remark is not empty\n","                labeled_data_for_training.append({\n","                    'remark_original': str(remark_entry), # Keep original for reference\n","                    'remark_cleaned': cleaned_remark,\n","                    'category': standard_category_label # Use the standardized label\n","                })\n","\n","    # Create the DataFrame for training\n","    df_labeled_for_training = pd.DataFrame(labeled_data_for_training)\n","\n","    print(f\"\\nTransformed data for training shape: {df_labeled_for_training.shape}\")\n","    print(\"\\nFirst 5 rows of the transformed labeled data for training (remark_cleaned, category):\")\n","    print(df_labeled_for_training.head())\n","    print(\"\\nValue counts for 'category' (training labels):\")\n","    print(df_labeled_for_training['category'].value_counts())\n","    print(f\"\\nTotal unique categories identified in training data: {df_labeled_for_training['category'].nunique()}\")\n","\n","\n","except FileNotFoundError:\n","    print(f\"Error: The file '{excel_file_path}' was not found. Please ensure it's in the same directory as this script.\")\n","    exit()\n","except Exception as e:\n","    print(f\"An unexpected error occurred: {e}\")\n","    import traceback\n","    traceback.print_exc()\n","    exit()\n","\n","# Store relevant data for the next steps\n","global_df_labeled_for_training = df_labeled_for_training\n","global_original_category_column_names = desired_category_labels # These are the names we will use for output columns, ensuring uniqueness"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Mv0qdrvYHCb","executionInfo":{"status":"ok","timestamp":1753688993518,"user_tz":-330,"elapsed":686,"user":{"displayName":"Aadi","userId":"17429767985240166296"}},"outputId":"ad4a3b22-eacd-4a1e-8804-8afe77229785"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Successfully loaded './DATA.xlsx'. Shape: (1152, 12)\n","\n","First 5 rows of the raw data (DATA.xlsx content):\n","  Bill Accuracy and Discrepancies  \\\n","0                             NaN   \n","1               bill online shilp   \n","2                             NaN   \n","3               Last bill is over   \n","4                             NaN   \n","\n","             Bill Content and Delivery Discrepancies  \\\n","0                                                NaN   \n","1  Consumers Problem : wrong Bill (Domestic 2 kw ...   \n","2                                                NaN   \n","3  Consumers Problem : Bill Not Update (Domestic ...   \n","4                                                NaN   \n","\n","                Bill Hold Preventing Online Payments  \\\n","0                                                NaN   \n","1                             Online payment service   \n","2                                                NaN   \n","3  CONSUMER REQUEST BILL ON HOLD ALSO BILL WRONG ...   \n","4                                                NaN   \n","\n","         Billing Discrepancies Due to Meter Readings  \\\n","0                                                NaN   \n","1  Wrong reading bill given I submitted applicati...   \n","2                                                NaN   \n","3               Feb and march month reading is wrong   \n","4                                                NaN   \n","\n","  Customer Billing Not Received or Available  \\\n","0                                        NaN   \n","1                          Bill not received   \n","2                                        NaN   \n","3                          Bill not recieved   \n","4                                        NaN   \n","\n","              Customer Reported Billing Inaccuracies  \\\n","0                                                NaN   \n","1  Consumer Problem-WRONG BILL RECEIVED From When...   \n","2                                                NaN   \n","3  BILL SE RALATED COMPLAINT BUT CONSUMER SIDE CA...   \n","4                                                NaN   \n","\n","           Domestic Connection Billing Discrepancies  \\\n","0                                                NaN   \n","1  Consumer Problem- Wrong Bill Consumer Connecti...   \n","2                                                NaN   \n","3  Consumer Problem- Wrong Bill Consumer Connecti...   \n","4                                                NaN   \n","\n","           Domestic Meter Reading Collection Failure  \\\n","0                                                NaN   \n","1  Consumer Connection Type- Domestic Consumer Pr...   \n","2                                                NaN   \n","3  Consumer Problem- Meter Reading Not Done Consu...   \n","4                                                NaN   \n","\n","      Electricity Bill Discrepancies and Solar Units  \\\n","0                                                NaN   \n","1  Miscellaneous charges are too high and no dedu...   \n","2                                                NaN   \n","3  My billed unit is very high my June bill unit ...   \n","4                                                NaN   \n","\n","  Rectifying Account and Billing Discrepancies  \\\n","0                                          NaN   \n","1               Bil not updated since may 2025   \n","2                                          NaN   \n","3                                   Wrong Load   \n","4                                          NaN   \n","\n","        Unacknowledged Customer Payments and Billing  \\\n","0                                                NaN   \n","1  I paid my last month's bill yesterday, but thi...   \n","2                                                NaN   \n","3                            Billing SMS not receive   \n","4                                                NaN   \n","\n","                    Other Language Remarks  \n","0                                      NaN  \n","1  10 din Mein Mera bil double ho gaya hai  \n","2                                      NaN  \n","3         25 unit ka bill Rs.864 banaya he  \n","4                                      NaN  \n","\n","Columns (Categories) identified from the raw data:\n","['Bill Accuracy and Discrepancies', 'Bill Content and Delivery Discrepancies', 'Bill Hold Preventing Online Payments', 'Billing Discrepancies Due to Meter Readings', 'Customer Billing Not Received or Available', 'Customer Reported Billing Inaccuracies', 'Domestic Connection Billing Discrepancies', 'Domestic Meter Reading Collection Failure', 'Electricity Bill Discrepancies and Solar Units', 'Rectifying Account and Billing Discrepancies', 'Unacknowledged Customer Payments and Billing', 'Other Language Remarks']\n","Warning: Column 'Customer Reported Billing Inaccuracies' from Excel file is not in the list of desired categories. It will be ignored for training data. If this is a category, please add it to 'desired_category_labels'.\n","Warning: Column 'Domestic Meter Reading Collection Failure' from Excel file is not in the list of desired categories. It will be ignored for training data. If this is a category, please add it to 'desired_category_labels'.\n","Warning: Column 'Electricity Bill Discrepancies and Solar Units' from Excel file is not in the list of desired categories. It will be ignored for training data. If this is a category, please add it to 'desired_category_labels'.\n","Warning: Column 'Rectifying Account and Billing Discrepancies' from Excel file is not in the list of desired categories. It will be ignored for training data. If this is a category, please add it to 'desired_category_labels'.\n","Warning: Column 'Unacknowledged Customer Payments and Billing' from Excel file is not in the list of desired categories. It will be ignored for training data. If this is a category, please add it to 'desired_category_labels'.\n","\n","Identified 7 Unique Category Labels for Training:\n","['Bill Accuracy and Discrepancies', 'Bill Content and Delivery Discrepancies', 'Domestic Connection Billing Discrepancies', 'Customer Billing Not Received or Available', 'Billing Discrepancies Due to Meter Readings', 'Other Language Remarks', 'Bill Hold Preventing Online Payments']\n","\n","Columns from Excel file that will be processed (including any pandas-generated suffixes):\n","['Bill Accuracy and Discrepancies', 'Bill Content and Delivery Discrepancies', 'Bill Hold Preventing Online Payments', 'Billing Discrepancies Due to Meter Readings', 'Customer Billing Not Received or Available', 'Domestic Connection Billing Discrepancies', 'Other Language Remarks']\n","\n","Transformed data for training shape: (2015, 3)\n","\n","First 5 rows of the transformed labeled data for training (remark_cleaned, category):\n","            remark_original            remark_cleaned  \\\n","0         bill online shilp         bill online shilp   \n","1         Last bill is over         last bill is over   \n","2            Bill incorrect            bill incorrect   \n","3             Bill realated             bill realated   \n","4  Bill riseved not correct  bill riseved not correct   \n","\n","                          category  \n","0  Bill Accuracy and Discrepancies  \n","1  Bill Accuracy and Discrepancies  \n","2  Bill Accuracy and Discrepancies  \n","3  Bill Accuracy and Discrepancies  \n","4  Bill Accuracy and Discrepancies  \n","\n","Value counts for 'category' (training labels):\n","category\n","Customer Billing Not Received or Available     576\n","Domestic Connection Billing Discrepancies      372\n","Bill Accuracy and Discrepancies                322\n","Billing Discrepancies Due to Meter Readings    270\n","Other Language Remarks                         252\n","Bill Content and Delivery Discrepancies        178\n","Bill Hold Preventing Online Payments            45\n","Name: count, dtype: int64\n","\n","Total unique categories identified in training data: 7\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report, accuracy_score\n","from sentence_transformers import SentenceTransformer\n","import time\n","import torch\n","\n","# Ensure global_df_labeled_for_training is available from Step 1\n","if 'global_df_labeled_for_training' not in globals():\n","    print(\"Error: global_df_labeled_for_training not found. Please run Step 1 code first.\")\n","    exit()\n","\n","df_training = global_df_labeled_for_training.copy()\n","\n","print(\"\\n--- Step 2: Feature Extraction (Sentence Embeddings) and Model Training (Logistic Regression) ---\")\n","\n","# --- Step 2.1: Split Data into Training and Testing Sets ---\n","# X will be the cleaned remarks, y will be the categories\n","X = df_training['remark_cleaned'].tolist() # Convert to list for SentenceTransformer\n","y = df_training['category'].tolist()\n","\n","# Stratify ensures that the proportion of categories is maintained in both train and test sets\n","# This is crucial for imbalanced datasets.\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n","\n","print(f\"Dataset split: Training samples: {len(X_train)}, Testing samples: {len(X_test)}\")\n","print(f\"Unique categories in training set: {len(set(y_train))}\")\n","print(f\"Unique categories in testing set: {len(set(y_test))}\")\n","\n","\n","# --- Step 2.2: Generate Sentence Embeddings ---\n","print(\"Loading SentenceTransformer model...\")\n","# Using 'all-MiniLM-L6-v2' as it's efficient and performs well.\n","# Ensure you have a GPU for 'cuda' device, otherwise use 'cpu'.\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","model_embedding = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n","print(f\"SentenceTransformer model loaded on device: {device}\")\n","\n","print(\"Generating embeddings for training data...\")\n","start_time_embed_train = time.time()\n","X_train_embeddings = model_embedding.encode(X_train, show_progress_bar=True, convert_to_numpy=True)\n","print(f\"Training embeddings generated in {time.time() - start_time_embed_train:.2f} seconds.\")\n","\n","print(\"Generating embeddings for testing data...\")\n","start_time_embed_test = time.time()\n","X_test_embeddings = model_embedding.encode(X_test, show_progress_bar=True, convert_to_numpy=True)\n","print(f\"Testing embeddings generated in {time.time() - start_time_embed_test:.2f} seconds.\")\n","\n","print(f\"Shape of training embeddings: {X_train_embeddings.shape}\")\n","print(f\"Shape of testing embeddings: {X_test_embeddings.shape}\")\n","\n","\n","# --- Step 2.3: Train a Classification Model (Logistic Regression) ---\n","print(\"\\nTraining Logistic Regression model...\")\n","start_time_train_model = time.time()\n","\n","# Logistic Regression parameters:\n","# max_iter: Increased for convergence with larger datasets/complex features\n","# solver: 'liblinear' is good for smaller datasets; 'lbfgs' is good for larger ones.\n","# 'lbfgs' also supports multi_class='multinomial' for true multi-class classification.\n","# class_weight: 'balanced' can help with imbalanced datasets by giving more weight to minority classes.\n","classifier_model = LogisticRegression(\n","    max_iter=1000,\n","    solver='lbfgs', # 'liblinear' or 'lbfgs' or 'saga'\n","    multi_class='auto', # or 'multinomial' for lbfgs\n","    class_weight='balanced', # Important for imbalanced classes\n","    random_state=42,\n","    n_jobs=-1 # Use all available CPU cores\n",")\n","\n","classifier_model.fit(X_train_embeddings, y_train)\n","print(f\"Logistic Regression model trained in {time.time() - start_time_train_model:.2f} seconds.\")\n","\n","\n","# --- Step 2.4: Evaluate the Model ---\n","print(\"\\n--- Model Evaluation ---\")\n","y_pred = classifier_model.predict(X_test_embeddings)\n","\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Overall Accuracy: {accuracy:.4f}\")\n","\n","# Detailed classification report\n","print(\"\\nClassification Report:\")\n","print(classification_report(y_test, y_pred, zero_division=0)) # zero_division=0 avoids warning for classes with no true samples in test set\n","\n","# Store models and data for next step\n","global_model_embedding = model_embedding\n","global_classifier_model = classifier_model\n","global_y_test = y_test\n","global_y_pred = y_pred\n","\n","print(\"\\nStep 2 completed. Review the accuracy and classification report.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":812,"referenced_widgets":["62dd843fb86a4c81bc45de16836b9ab0","86922d8602a34e55b544569148fad9d3","7959bb4c43c942cd869c1643922bf7a1","fa0589f2159642e8b634d51db1f1dda7","cf9a066b5ddc4664909a310e008b8892","b99560b984e14f67944d517d62adb21a","8b5b323640934a1ba65f15ca9ba29257","caeba5d28864423b9c140dc43e874abf","abb7cff50e724749a1a1d1a3cac27378","9e8c72625a684771956b191e5f8dc6c4","69d76ab0e50349f68844ba28d47788ef","71ff0a74c0fd4460a7c3932acb8dee74","b848296d63c547dfbe2a627aec4c3283","9e18358527204739b1dcd7cc5d21ae60","be3b3f2807964974bff8acf1b07e67ac","cbb902550e224987a17480aa465ace8c","31a7932b34864ae09e589fe1adf249be","bbc99a0c4520491eb460a4a50b908e3d","172b25e57daa481f962c90929b49587a","b9397583369646619be29c53db9832ea","7114a91d1cfd4356943032c31e9fe774","5d5de136e3aa4ffe97ff46a3db93bde5"]},"id":"nxd82hgEYejU","executionInfo":{"status":"ok","timestamp":1753689006620,"user_tz":-330,"elapsed":2904,"user":{"displayName":"Aadi","userId":"17429767985240166296"}},"outputId":"96590f27-a9f3-4d3e-9857-26cc8c70b03a"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Step 2: Feature Extraction (Sentence Embeddings) and Model Training (Logistic Regression) ---\n","Dataset split: Training samples: 1612, Testing samples: 403\n","Unique categories in training set: 7\n","Unique categories in testing set: 7\n","Loading SentenceTransformer model...\n","SentenceTransformer model loaded on device: cuda\n","Generating embeddings for training data...\n"]},{"output_type":"display_data","data":{"text/plain":["Batches:   0%|          | 0/51 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62dd843fb86a4c81bc45de16836b9ab0"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Training embeddings generated in 0.43 seconds.\n","Generating embeddings for testing data...\n"]},{"output_type":"display_data","data":{"text/plain":["Batches:   0%|          | 0/13 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71ff0a74c0fd4460a7c3932acb8dee74"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Testing embeddings generated in 0.12 seconds.\n","Shape of training embeddings: (1612, 384)\n","Shape of testing embeddings: (403, 384)\n","\n","Training Logistic Regression model...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Logistic Regression model trained in 1.46 seconds.\n","\n","--- Model Evaluation ---\n","Overall Accuracy: 0.9826\n","\n","Classification Report:\n","                                             precision    recall  f1-score   support\n","\n","            Bill Accuracy and Discrepancies       0.91      1.00      0.96        64\n","    Bill Content and Delivery Discrepancies       1.00      1.00      1.00        36\n","       Bill Hold Preventing Online Payments       1.00      1.00      1.00         9\n","Billing Discrepancies Due to Meter Readings       1.00      1.00      1.00        54\n"," Customer Billing Not Received or Available       0.99      0.98      0.99       115\n","  Domestic Connection Billing Discrepancies       1.00      1.00      1.00        74\n","                     Other Language Remarks       1.00      0.90      0.95        51\n","\n","                                   accuracy                           0.98       403\n","                                  macro avg       0.99      0.98      0.98       403\n","                               weighted avg       0.98      0.98      0.98       403\n","\n","\n","Step 2 completed. Review the accuracy and classification report.\n"]}]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import re\n","import numpy as np\n","from collections import defaultdict\n","from nltk.corpus import stopwords as nltk_stopwords\n","import nltk\n","from sentence_transformers import SentenceTransformer\n","from joblib import Parallel, delayed\n","import time\n","import torch\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report, accuracy_score\n","from sklearn.preprocessing import StandardScaler\n","import joblib\n","\n","# Download NLTK stopwords\n","try:\n","    nltk.data.find('corpora/stopwords')\n","except LookupError:\n","    nltk.download('stopwords')\n","\n","# Define stopwords (from your original code, ensure consistency)\n","UNIVERSAL_STOPWORDS = set(nltk_stopwords.words('english') + [\n","    'the', 'area', 'a', 'an', 'and', 'or', 'but', 'is', 'are', 'was', 'were', 'to', 'of', 'in', 'for', 'on', 'with', 'at', 'from', 'by', 'this', 'that', 'it', 'its', 'her', 'their', 'our',\n","    'what', 'where', 'how', 'why', 'who', 'whom', 'which', 'whether',\n","    'yesterday', 'today', 'tomorrow', 'morning', 'evening', 'night', 'day', 'days', 'hr', 'hrs', 'hour', 'hours', 'time', 'date', 'week', 'month', 'year', 'ago',\n","    'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'zero',\n","    'consumer', 'customer', 'number', 'no', 'code', 'id', 'location', 'address', 'phone', 'mobile', 'call', 'report', 'registered',\n","    'ok', 'yes', 'no', 'not', 'hi', 'hello', 'sir', 'madam', 'pls', 'please', 'regards', 'type', 'urban', 'complaint', 'detail', 'general',\n","    'kv', 'tf', 'na', 'service', 'request', 'feedback', 'query', 'regarding', 'about', 'given', 'areas', 'village'\n","])\n","\n","def clean_text(text: str) -> str:\n","    \"\"\"Removes extra whitespace and standardizes text (generic version).\"\"\"\n","    if pd.isna(text):\n","        return \"\"\n","    text = str(text) # Ensure text is a string\n","\n","    # Remove any stray non-alphanumeric characters that might remain after emoji removal,\n","    # then handle whitespace and lowercase.\n","    # Keep alphanumeric characters and basic punctuation that might be relevant to remarks\n","    text = re.sub(r'[^a-zA-Z0-9\\s.,!?\\'\"-/]', '', text)\n","    text = re.sub(r'\\s+', ' ', text.strip()).lower()\n","    return text\n","\n","def extract_time_features(remarks_series: pd.Series) -> pd.DataFrame:\n","    \"\"\"\n","    Extracts numerical time features (hours, presence of AM/PM) from a Series of remarks.\n","    Returns a DataFrame with these features.\n","    \"\"\"\n","    remarks_series = remarks_series.fillna(\"\").str.lower()\n","\n","    hour_pattern = r'(\\d+\\.?\\d*)\\s*(?:hr|hrs|hour|hours|h)'\n","    day_pattern = r'(\\d+\\.?\\d*)\\s*(?:day|days)'\n","    am_pm_pattern = r'\\b(\\d{1,2}(:\\d{2})?)\\s*(am|pm)\\b'\n","\n","    hours_extracted = remarks_series.str.extract(hour_pattern)[0].astype(float).fillna(0)\n","    days_extracted = remarks_series.str.extract(day_pattern)[0].astype(float).fillna(0)\n","\n","    hours_from_days = days_extracted * 24\n","    combined_hours = hours_extracted + hours_from_days\n","\n","    is_am_pm_mentioned = remarks_series.str.contains(am_pm_pattern, regex=True).astype(int)\n","\n","    return pd.DataFrame({\n","        'extracted_hours': combined_hours,\n","        'is_am_pm_mentioned': is_am_pm_mentioned\n","    })\n","\n","\n","def main_classification_pipeline():\n","    # --- Configuration ---\n","    labeled_data_excel_path = \"./DATA.xlsx\"\n","    new_remarks_excel_path = \"./Bill.xlsx\"\n","    output_excel_path = \"./categorized_remarks_ML_model_compacted_time_aware.xlsx\" # Output filename\n","    \"\"\"\n","    # for supply\n","    desired_category_labels = [\n","        \"Less than 4 hours\",\n","        \"More than 12 hours\",\n","        \"More than 24 hours\",\n","        \"More than 4 hours\",\n","        \"Consumer Power Supply Failures\",\n","        \"Failed Pole Incident Category\",\n","        \"Other Language Remarks\",\n","        \"Partial Phase Supply Failure\",\n","        \"Transformer Damage Causing Outages\"\n","    ]\n","    \"\"\"\n","    desired_category_labels = [\n","        \"Bill Accuracy and Discrepancies\",\n","        \"Bill Content and Delivery Discrepancies\",\n","        \"Bill Hold Preventing Online Payments\",\n","        \"Billing Discrepancies Due to Meter Readings\",\n","        \"Customer Billing Not Received or Available\",\n","        \"Customer Reported Billing Inaccuracie\",\n","        \"Other Language Remarks\",\n","        \"Domestic Connection Billing Discrepancies\",\n","        \"Domestic Meter Reading Collection Failure\"\n","        \"Electricity Bill Discrepancies and Solar Units\"\n","        \"Rectifying Account and Billing Discrepancies\"\n","        \"Unacknowledged Customer Payments and Billing\"\n","    ]\n","\n","    # Column containing remarks in the NEW_REMARKS_EXCEL_PATH file (e.g., Supply.xlsx)\n","    remarks_column_in_new_file = \"REMARKS\"\n","\n","    print(\"--- Starting Supervised ML Remark Categorization Pipeline (Time-Aware) ---\")\n","    start_full_pipeline_time = time.time()\n","\n","    # --- Step 1: Data Preparation for Training ---\n","    print(\"\\n--- Step 1: Data Preparation for Training ---\")\n","    try:\n","        df_raw_labeled = pd.read_excel(labeled_data_excel_path, header=0)\n","        print(f\"Successfully loaded '{labeled_data_excel_path}'. Shape: {df_raw_labeled.shape}\")\n","        print(\"First 5 rows of the raw labeled data:\")\n","        print(df_raw_labeled.head())\n","        print(\"Columns identified from the raw labeled data:\")\n","        print(df_raw_labeled.columns.tolist())\n","\n","        loaded_to_label_map = {}\n","        seen_labels = {}\n","\n","        for col in df_raw_labeled.columns:\n","            normalized_col = col.split('.')[0]\n","\n","            if normalized_col in desired_category_labels:\n","                if normalized_col in seen_labels:\n","                    loaded_to_label_map[col] = normalized_col\n","                else:\n","                    loaded_to_label_map[col] = col\n","                    seen_labels[normalized_col] = True\n","            else:\n","                print(f\"Warning: Column '{col}' from '{labeled_data_excel_path}' is not in the list of desired categories. It will be ignored for training data. If this is a category, please add it to 'desired_category_labels'.\")\n","\n","        active_category_columns_in_df = list(loaded_to_label_map.keys())\n","\n","        print(f\"\\nIdentified {len(set(loaded_to_label_map.values()))} Unique Category Labels for Training:\")\n","        print(list(set(loaded_to_label_map.values())))\n","        print(f\"Columns from '{labeled_data_excel_path}' that will be processed:\")\n","        print(active_category_columns_in_df)\n","\n","        labeled_data_for_training = []\n","        for category_col_in_df in active_category_columns_in_df:\n","            standard_category_label = loaded_to_label_map[category_col_in_df]\n","            for remark_entry in df_raw_labeled[category_col_in_df].dropna():\n","                cleaned_remark = clean_text(str(remark_entry))\n","                if cleaned_remark:\n","                    labeled_data_for_training.append({\n","                        'remark_original': str(remark_entry),\n","                        'remark_cleaned': cleaned_remark,\n","                        'category': standard_category_label\n","                    })\n","\n","        df_labeled_for_training = pd.DataFrame(labeled_data_for_training)\n","        print(f\"\\nTransformed data for training shape: {df_labeled_for_training.shape}\")\n","        print(\"First 5 rows of the transformed labeled data for training:\")\n","        print(df_labeled_for_training.head())\n","        print(\"Value counts for 'category' (training labels):\")\n","        print(df_labeled_for_training['category'].value_counts())\n","        print(f\"Total unique categories identified in training data: {df_labeled_for_training['category'].nunique()}\")\n","\n","    except FileNotFoundError:\n","        print(f\"ERROR: The file '{labeled_data_excel_path}' not found. Please ensure it's in the same directory.\")\n","        return\n","    except Exception as e:\n","        print(f\"ERROR in Step 1: {e}\")\n","        import traceback; traceback.print_exc()\n","        return\n","\n","    # --- Step 2: Feature Extraction (Sentence Embeddings + Time Features) and Model Training ---\n","    print(\"\\n--- Step 2: Feature Extraction (Sentence Embeddings + Time Features) and Model Training ---\")\n","    try:\n","        X_train_data = df_labeled_for_training['remark_cleaned'].tolist()\n","        y_train_labels = df_labeled_for_training['category'].tolist()\n","\n","        X_train_text, X_test_text, y_train, y_test = train_test_split(\n","            pd.Series(X_train_data), y_train_labels, test_size=0.2, random_state=42, stratify=y_train_labels\n","        )\n","\n","        # Extract and scale time features for training\n","        scaler = StandardScaler() # Initialize scaler here\n","        X_train_time_features_df = extract_time_features(X_train_text)\n","        X_train_time_features_scaled = scaler.fit_transform(X_train_time_features_df)\n","\n","        X_test_time_features_df = extract_time_features(X_test_text)\n","        X_test_time_features_scaled = scaler.transform(X_test_time_features_df) # Use fitted scaler\n","\n","        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","        print(f\"Loading SentenceTransformer model on device: {device}...\")\n","        model_embedding = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n","\n","        print(\"Generating embeddings for training text...\")\n","        X_train_embeddings = model_embedding.encode(X_train_text.tolist(), show_progress_bar=True, convert_to_numpy=True)\n","        print(\"Generating embeddings for testing text...\")\n","        X_test_embeddings = model_embedding.encode(X_test_text.tolist(), show_progress_bar=True, convert_to_numpy=True)\n","\n","        X_train_combined_features = np.hstack((X_train_embeddings, X_train_time_features_scaled))\n","        X_test_combined_features = np.hstack((X_test_embeddings, X_test_time_features_scaled))\n","\n","        print(\"\\nTraining Logistic Regression model on combined features...\")\n","        classifier_model = LogisticRegression(\n","            max_iter=1000, solver='lbfgs', multi_class='auto', class_weight='balanced', random_state=42, n_jobs=-1\n","        )\n","        classifier_model.fit(X_train_combined_features, y_train)\n","        print(\"Logistic Regression model trained.\")\n","\n","        print(\"\\n--- Model Evaluation ---\")\n","        y_pred = classifier_model.predict(X_test_combined_features)\n","        print(f\"Overall Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n","        print(\"\\nClassification Report:\")\n","        print(classification_report(y_test, y_pred, zero_division=0))\n","\n","    except Exception as e:\n","        print(f\"ERROR in Step 2: {e}\")\n","        import traceback; traceback.print_exc()\n","        return\n","\n","    # --- Step 3: Prediction and Output Structuring ---\n","    print(\"\\n--- Step 3: Prediction and Output Structuring (Compacted Output) ---\")\n","    try:\n","        df_new_remarks_raw = pd.read_excel(new_remarks_excel_path)\n","        print(f\"Successfully loaded new remarks from '{new_remarks_excel_path}'. Shape: {df_new_remarks_raw.shape}\")\n","\n","        if remarks_column_in_new_file not in df_new_remarks_raw.columns:\n","            raise KeyError(f\"Column '{remarks_column_in_new_file}' not found in '{new_remarks_excel_path}'. Available columns: {df_new_remarks_raw.columns.tolist()}\")\n","\n","        new_remarks_data = []\n","        for idx, remark_raw in df_new_remarks_raw[remarks_column_in_new_file].items():\n","            cleaned = clean_text(remark_raw)\n","            if cleaned:\n","                new_remarks_data.append({'original_index': idx, 'remark_raw': remark_raw, 'remark_cleaned': cleaned})\n","\n","        df_remarks_to_classify = pd.DataFrame(new_remarks_data)\n","        print(f\"Extracted {len(df_remarks_to_classify)} valid remarks for classification.\")\n","\n","        print(\"\\nGenerating embeddings for new remarks...\")\n","        new_remarks_embeddings = model_embedding.encode(\n","            df_remarks_to_classify['remark_cleaned'].tolist(),\n","            show_progress_bar=True,\n","            convert_to_numpy=True\n","        )\n","\n","        # Extract and scale time features for new remarks\n","        print(\"Extracting and scaling time features for new remarks...\")\n","        new_remarks_time_features_df = extract_time_features(df_remarks_to_classify['remark_cleaned'])\n","        new_remarks_time_features_scaled = scaler.transform(new_remarks_time_features_df) # Use the *same* scaler from training\n","\n","        # Concatenate for prediction\n","        new_remarks_combined_features = np.hstack((new_remarks_embeddings, new_remarks_time_features_scaled))\n","\n","        print(\"\\nPredicting categories for new remarks...\")\n","        predicted_categories = classifier_model.predict(new_remarks_combined_features)\n","        df_remarks_to_classify['predicted_category'] = predicted_categories\n","        print(\"First 5 remarks with predicted categories:\")\n","        print(df_remarks_to_classify.head())\n","\n","        # --- MODIFIED PART FOR COMPACTED OUTPUT ---\n","        print(\"\\nCompacting output into wide format by pushing remarks to the top of each category column...\")\n","\n","        categorized_remarks_by_column = defaultdict(list)\n","\n","        for idx, row_data in df_remarks_to_classify.iterrows():\n","            remark = row_data['remark_raw']\n","            predicted_cat = row_data['predicted_category']\n","            categorized_remarks_by_column[predicted_cat].append(remark)\n","\n","        max_remarks_in_any_cat = 0\n","        if categorized_remarks_by_column:\n","            max_remarks_in_any_cat = max(len(v) for v in categorized_remarks_by_column.values())\n","\n","        df_output_compacted_wide = pd.DataFrame({\n","            col: categorized_remarks_by_column.get(col, []) + [''] * (max_remarks_in_any_cat - len(categorized_remarks_by_column.get(col, [])))\n","            for col in sorted(list(set(desired_category_labels)))\n","        })\n","\n","        print(f\"\\nFinal Compacted Wide Output DataFrame shape: {df_output_compacted_wide.shape}\")\n","        print(\"First 5 rows of the Final Compacted Wide Output DataFrame:\")\n","        print(df_output_compacted_wide.head())\n","\n","        print(f\"\\nSaving results to '{output_excel_path}'...\")\n","        df_output_compacted_wide.to_excel(output_excel_path, index=False)\n","        print(\"Results saved successfully.\")\n","\n","        # --- NEW LINES ADDED HERE FOR MODEL SAVING ---\n","        print(\"\\n--- Saving trained models for future use ---\")\n","        try:\n","            joblib.dump(model_embedding, 'sentence_transformer_model.pkl')\n","            joblib.dump(classifier_model, 'logistic_regression_classifier.pkl')\n","            joblib.dump(scaler, 'scaler_for_time_features.pkl')\n","            print(\"Models (Sentence Transformer, Classifier, Scaler) saved successfully to .pkl files.\")\n","        except Exception as e:\n","            print(f\"ERROR: Failed to save models: {e}\")\n","            import traceback; traceback.print_exc()\n","        # --- END OF NEW LINES ---\n","\n","        # --- Final Verification of Total Count ---\n","        print(\"\\n--- Final Verification of Total Count ---\")\n","        df_categorized_check = pd.read_excel(output_excel_path)\n","        print(f\"Shape of the re-loaded compacted categorized file: {df_categorized_check.shape}\")\n","\n","        total_categorized_remarks_from_file = 0\n","        for col in df_categorized_check.columns:\n","            total_categorized_remarks_from_file += df_categorized_check[col].apply(lambda x: pd.notna(x) and str(x).strip() != '').sum()\n","\n","        print(f\"Total number of remarks in the compacted categorized file (non-empty cell count): {total_categorized_remarks_from_file}\")\n","        print(f\"Number of remarks successfully extracted and classified (excluding empty after cleaning): {len(df_remarks_to_classify)}\")\n","\n","        if total_categorized_remarks_from_file == len(df_remarks_to_classify):\n","            print(\"All extracted and classified remarks successfully written to compacted output file.\")\n","        else:\n","            print(f\"Mismatch: {len(df_remarks_to_classify) - total_categorized_remarks_from_file} remarks missing from final file count. Investigate Excel saving/loading or if some cells are truly empty/NaN in source.\")\n","\n","    except FileNotFoundError:\n","        print(f\"ERROR: The file '{new_remarks_excel_path}' not found. Please ensure it's in the same directory.\")\n","        return\n","    except KeyError as e:\n","        print(f\"ERROR: Missing expected column in '{new_remarks_excel_path}'. Details: {e}\")\n","        if 'df_new_remarks_raw' in locals():\n","            print(\"Available columns in your Excel file are:\", df_new_remarks_raw.columns.tolist())\n","        return\n","    except Exception as e:\n","        print(f\"ERROR in Step 3: {e}\")\n","        import traceback; traceback.print_exc()\n","        return\n","\n","    print(f\"\\n--- Supervised ML Categorization Pipeline Completed in {time.time() - start_full_pipeline_time:.2f} seconds ---\")\n","\n","\n","if __name__ == \"__main__\":\n","    main_classification_pipeline()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["84c2601bc596458aba030b9d61fe38e2","0b82a6590acb493abd0921c5452c59a7","9e4dd6a0aced466890bc71b6ec868173","2da131e79fe24b4cadb0ff887c644aa2","e4a09bae9bad46afbf7d29646bbe2b74","56fba1f5cf8b4b83939edc2a0fea3a52","96cc2991268f489f8d49d5f62cf88462","e7d852bad16d48d4b5848f63a586098b","d01453946dc14f5e9557fff426809ad4","0a41f977b02d4236a3db134d95720337","8579b4ab27e14762b9098ef89367657f","8f3933d8d08b4fcfba52cd3b1710a5e6","d1e5835018494fa08ef1064447969ea5","d5b1b9d68f3e4c3fb6447292cf8f45f5","f7e34a44692a416fa8c4d40970a56d6c","b1dc78079f6d4fc882d8240cfabe7642","c0efffcd2c614c2daeb50e2750c140a2","2c04fb391a1f4363a7d8feb931353de9","b84bfe97008a4b45974f345cbf65ca3e","5f2d958834c145adbc784ff601bf87d1","ac289169fa3046e0b09da28b74c85ecf","6e9cb103f529413d9229b11347c661e6","4dc8d26d1e3344178ffbfb8525cf7485","02ec20c9164d48fe8d5b88a684178316","6394b4ccf4314c32b4fdd590d7017f09","d809d2ad634f499aaefe56db1cc3c806","102cc5fde9df4cb5aee8b14d8adba700","01bdb2a3bbd342008276be470f18698a","c6f7b9856acd43c0b2272015b7f456f3","b1f743936cf44b4eaa55b4c78289a845","4deb89b017134c9b9ae735387139eb99","3302426b02bc4647a15178b0ec5f9501","873d1cb52f2c49f892065976366e5483"]},"collapsed":true,"id":"S4o254cciJ4L","executionInfo":{"status":"ok","timestamp":1753689308385,"user_tz":-330,"elapsed":27219,"user":{"displayName":"Aadi","userId":"17429767985240166296"}},"outputId":"06b1a109-38c6-48af-eace-ca98110e775c"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Starting Supervised ML Remark Categorization Pipeline (Time-Aware) ---\n","\n","--- Step 1: Data Preparation for Training ---\n","Successfully loaded './DATA.xlsx'. Shape: (1152, 12)\n","First 5 rows of the raw labeled data:\n","  Bill Accuracy and Discrepancies  \\\n","0                             NaN   \n","1               bill online shilp   \n","2                             NaN   \n","3               Last bill is over   \n","4                             NaN   \n","\n","             Bill Content and Delivery Discrepancies  \\\n","0                                                NaN   \n","1  Consumers Problem : wrong Bill (Domestic 2 kw ...   \n","2                                                NaN   \n","3  Consumers Problem : Bill Not Update (Domestic ...   \n","4                                                NaN   \n","\n","                Bill Hold Preventing Online Payments  \\\n","0                                                NaN   \n","1                             Online payment service   \n","2                                                NaN   \n","3  CONSUMER REQUEST BILL ON HOLD ALSO BILL WRONG ...   \n","4                                                NaN   \n","\n","         Billing Discrepancies Due to Meter Readings  \\\n","0                                                NaN   \n","1  Wrong reading bill given I submitted applicati...   \n","2                                                NaN   \n","3               Feb and march month reading is wrong   \n","4                                                NaN   \n","\n","  Customer Billing Not Received or Available  \\\n","0                                        NaN   \n","1                          Bill not received   \n","2                                        NaN   \n","3                          Bill not recieved   \n","4                                        NaN   \n","\n","              Customer Reported Billing Inaccuracies  \\\n","0                                                NaN   \n","1  Consumer Problem-WRONG BILL RECEIVED From When...   \n","2                                                NaN   \n","3  BILL SE RALATED COMPLAINT BUT CONSUMER SIDE CA...   \n","4                                                NaN   \n","\n","           Domestic Connection Billing Discrepancies  \\\n","0                                                NaN   \n","1  Consumer Problem- Wrong Bill Consumer Connecti...   \n","2                                                NaN   \n","3  Consumer Problem- Wrong Bill Consumer Connecti...   \n","4                                                NaN   \n","\n","           Domestic Meter Reading Collection Failure  \\\n","0                                                NaN   \n","1  Consumer Connection Type- Domestic Consumer Pr...   \n","2                                                NaN   \n","3  Consumer Problem- Meter Reading Not Done Consu...   \n","4                                                NaN   \n","\n","      Electricity Bill Discrepancies and Solar Units  \\\n","0                                                NaN   \n","1  Miscellaneous charges are too high and no dedu...   \n","2                                                NaN   \n","3  My billed unit is very high my June bill unit ...   \n","4                                                NaN   \n","\n","  Rectifying Account and Billing Discrepancies  \\\n","0                                          NaN   \n","1               Bil not updated since may 2025   \n","2                                          NaN   \n","3                                   Wrong Load   \n","4                                          NaN   \n","\n","        Unacknowledged Customer Payments and Billing  \\\n","0                                                NaN   \n","1  I paid my last month's bill yesterday, but thi...   \n","2                                                NaN   \n","3                            Billing SMS not receive   \n","4                                                NaN   \n","\n","                    Other Language Remarks  \n","0                                      NaN  \n","1  10 din Mein Mera bil double ho gaya hai  \n","2                                      NaN  \n","3         25 unit ka bill Rs.864 banaya he  \n","4                                      NaN  \n","Columns identified from the raw labeled data:\n","['Bill Accuracy and Discrepancies', 'Bill Content and Delivery Discrepancies', 'Bill Hold Preventing Online Payments', 'Billing Discrepancies Due to Meter Readings', 'Customer Billing Not Received or Available', 'Customer Reported Billing Inaccuracies', 'Domestic Connection Billing Discrepancies', 'Domestic Meter Reading Collection Failure', 'Electricity Bill Discrepancies and Solar Units', 'Rectifying Account and Billing Discrepancies', 'Unacknowledged Customer Payments and Billing', 'Other Language Remarks']\n","Warning: Column 'Customer Reported Billing Inaccuracies' from './DATA.xlsx' is not in the list of desired categories. It will be ignored for training data. If this is a category, please add it to 'desired_category_labels'.\n","Warning: Column 'Domestic Meter Reading Collection Failure' from './DATA.xlsx' is not in the list of desired categories. It will be ignored for training data. If this is a category, please add it to 'desired_category_labels'.\n","Warning: Column 'Electricity Bill Discrepancies and Solar Units' from './DATA.xlsx' is not in the list of desired categories. It will be ignored for training data. If this is a category, please add it to 'desired_category_labels'.\n","Warning: Column 'Rectifying Account and Billing Discrepancies' from './DATA.xlsx' is not in the list of desired categories. It will be ignored for training data. If this is a category, please add it to 'desired_category_labels'.\n","Warning: Column 'Unacknowledged Customer Payments and Billing' from './DATA.xlsx' is not in the list of desired categories. It will be ignored for training data. If this is a category, please add it to 'desired_category_labels'.\n","\n","Identified 7 Unique Category Labels for Training:\n","['Bill Accuracy and Discrepancies', 'Bill Content and Delivery Discrepancies', 'Domestic Connection Billing Discrepancies', 'Customer Billing Not Received or Available', 'Billing Discrepancies Due to Meter Readings', 'Other Language Remarks', 'Bill Hold Preventing Online Payments']\n","Columns from './DATA.xlsx' that will be processed:\n","['Bill Accuracy and Discrepancies', 'Bill Content and Delivery Discrepancies', 'Bill Hold Preventing Online Payments', 'Billing Discrepancies Due to Meter Readings', 'Customer Billing Not Received or Available', 'Domestic Connection Billing Discrepancies', 'Other Language Remarks']\n","\n","Transformed data for training shape: (1981, 3)\n","First 5 rows of the transformed labeled data for training:\n","            remark_original            remark_cleaned  \\\n","0         bill online shilp         bill online shilp   \n","1         Last bill is over         last bill is over   \n","2            Bill incorrect            bill incorrect   \n","3             Bill realated             bill realated   \n","4  Bill riseved not correct  bill riseved not correct   \n","\n","                          category  \n","0  Bill Accuracy and Discrepancies  \n","1  Bill Accuracy and Discrepancies  \n","2  Bill Accuracy and Discrepancies  \n","3  Bill Accuracy and Discrepancies  \n","4  Bill Accuracy and Discrepancies  \n","Value counts for 'category' (training labels):\n","category\n","Customer Billing Not Received or Available     576\n","Domestic Connection Billing Discrepancies      372\n","Bill Accuracy and Discrepancies                322\n","Billing Discrepancies Due to Meter Readings    270\n","Other Language Remarks                         218\n","Bill Content and Delivery Discrepancies        178\n","Bill Hold Preventing Online Payments            45\n","Name: count, dtype: int64\n","Total unique categories identified in training data: 7\n","\n","--- Step 2: Feature Extraction (Sentence Embeddings + Time Features) and Model Training ---\n","Loading SentenceTransformer model on device: cuda...\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-14-367821598.py:65: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n","  is_am_pm_mentioned = remarks_series.str.contains(am_pm_pattern, regex=True).astype(int)\n","/tmp/ipython-input-14-367821598.py:65: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n","  is_am_pm_mentioned = remarks_series.str.contains(am_pm_pattern, regex=True).astype(int)\n"]},{"output_type":"stream","name":"stdout","text":["Generating embeddings for training text...\n"]},{"output_type":"display_data","data":{"text/plain":["Batches:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84c2601bc596458aba030b9d61fe38e2"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Generating embeddings for testing text...\n"]},{"output_type":"display_data","data":{"text/plain":["Batches:   0%|          | 0/13 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f3933d8d08b4fcfba52cd3b1710a5e6"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Training Logistic Regression model on combined features...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Logistic Regression model trained.\n","\n","--- Model Evaluation ---\n","Overall Accuracy: 0.9824\n","\n","Classification Report:\n","                                             precision    recall  f1-score   support\n","\n","            Bill Accuracy and Discrepancies       0.94      1.00      0.97        64\n","    Bill Content and Delivery Discrepancies       1.00      1.00      1.00        36\n","       Bill Hold Preventing Online Payments       1.00      1.00      1.00         9\n","Billing Discrepancies Due to Meter Readings       0.98      1.00      0.99        54\n"," Customer Billing Not Received or Available       0.99      0.98      0.99       115\n","  Domestic Connection Billing Discrepancies       1.00      1.00      1.00        75\n","                     Other Language Remarks       0.97      0.89      0.93        44\n","\n","                                   accuracy                           0.98       397\n","                                  macro avg       0.98      0.98      0.98       397\n","                               weighted avg       0.98      0.98      0.98       397\n","\n","\n","--- Step 3: Prediction and Output Structuring (Compacted Output) ---\n","Successfully loaded new remarks from './Bill.xlsx'. Shape: (60729, 1)\n","Extracted 51459 valid remarks for classification.\n","\n","Generating embeddings for new remarks...\n"]},{"output_type":"display_data","data":{"text/plain":["Batches:   0%|          | 0/1609 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4dc8d26d1e3344178ffbfb8525cf7485"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Extracting and scaling time features for new remarks...\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-14-367821598.py:65: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n","  is_am_pm_mentioned = remarks_series.str.contains(am_pm_pattern, regex=True).astype(int)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Predicting categories for new remarks...\n","First 5 remarks with predicted categories:\n","   original_index                                         remark_raw  \\\n","0               0    Consumers Problem : wrong  Bill  (Domestic 2...   \n","1               1   Consumer Problem- Wrong Bill\\t\\t\\t\\t\\nConsume...   \n","2               2   Consumer Problem- Wrong Bill\\t\\t\\t\\t\\nConsume...   \n","3               3   Consumers Problem : Bill Not Received to  …2…...   \n","4               4   Consumers Problem : Bill Not Update (Domestic...   \n","\n","                                      remark_cleaned  \\\n","0  consumers problem wrong bill (domestic 2 kw ) ...   \n","1  consumer problem- wrong bill consumer connecti...   \n","2  consumer problem- wrong bill consumer connecti...   \n","3  consumers problem bill not received to 2.. mon...   \n","4  consumers problem bill not update (domestic / ...   \n","\n","                          predicted_category  \n","0    Bill Content and Delivery Discrepancies  \n","1  Domestic Connection Billing Discrepancies  \n","2  Domestic Connection Billing Discrepancies  \n","3  Domestic Connection Billing Discrepancies  \n","4    Bill Content and Delivery Discrepancies  \n","\n","Compacting output into wide format by pushing remarks to the top of each category column...\n","\n","Final Compacted Wide Output DataFrame shape: (26194, 9)\n","First 5 rows of the Final Compacted Wide Output DataFrame:\n","  Bill Accuracy and Discrepancies  \\\n","0               Bill amount extra   \n","1            Bill amount is wrong   \n","2                Bill not updated   \n","3               bill online shilp   \n","4                     Riding bill   \n","\n","             Bill Content and Delivery Discrepancies  \\\n","0    Consumers Problem : wrong  Bill  (Domestic 2...   \n","1   Consumers Problem : Bill Not Update (Domestic...   \n","2   Consumers Problem : Fictious Arrear Related I...   \n","3   Consumers Problem : He has Received wrong bil...   \n","4   Consumers Problem : He has Received wrong bil...   \n","\n","                Bill Hold Preventing Online Payments  \\\n","0  This is to bring to your attention that an amo...   \n","1  Payment amount and bill amount is different on...   \n","2  We have already paid the bill for an amount of...   \n","3  I have paid amount of due bill pey ment but co...   \n","4        Billed Demand Extra load without my consent   \n","\n","         Billing Discrepancies Due to Meter Readings  \\\n","0  Consumers Problem : Meter Reader Not Come To T...   \n","1  Consumers Problem : Meter Reader not come to t...   \n","2  Here meter reading not done we have wrong bill...   \n","3    Meter load entered incorrectly make it correct.   \n","4  Wrong reading bill given I submitted applicati...   \n","\n","          Customer Billing Not Received or Available  \\\n","0                                  Bill not received   \n","1  Bill not updated and smart meter replaced by o...   \n","2  I paid my last month''s bill yesterday, but th...   \n","3                            Irregular billing cycle   \n","4  Bill update high amount and show previous 2 ye...   \n","\n","  Customer Reported Billing Inaccuracie  \\\n","0                                         \n","1                                         \n","2                                         \n","3                                         \n","4                                         \n","\n","           Domestic Connection Billing Discrepancies  \\\n","0   Consumer Problem- Wrong Bill\\t\\t\\t\\t\\nConsume...   \n","1   Consumer Problem- Wrong Bill\\t\\t\\t\\t\\nConsume...   \n","2   Consumers Problem : Bill Not Received to  …2…...   \n","3   Consumers Problem : He has Received wrong bil...   \n","4   Consumers Problem : He has Received wrong bil...   \n","\n","  Domestic Meter Reading Collection FailureElectricity Bill Discrepancies and Solar UnitsRectifying Account and Billing DiscrepanciesUnacknowledged Customer Payments and Billing  \\\n","0                                                                                                                                                                                   \n","1                                                                                                                                                                                   \n","2                                                                                                                                                                                   \n","3                                                                                                                                                                                   \n","4                                                                                                                                                                                   \n","\n","                              Other Language Remarks  \n","0            10 din Mein Mera bil double ho gaya hai  \n","1                   25 unit ka bill Rs.864 banaya he  \n","2  7 mahine Bill bnane koi nahi aya or bill 931 a...  \n","3                         Bil apdet nhi kiya gya hai  \n","4                      Bil galat nikalta hai har bar  \n","\n","Saving results to './categorized_remarks_ML_model_compacted_time_aware.xlsx'...\n","Results saved successfully.\n","\n","--- Saving trained models for future use ---\n","Models (Sentence Transformer, Classifier, Scaler) saved successfully to .pkl files.\n","\n","--- Final Verification of Total Count ---\n","Shape of the re-loaded compacted categorized file: (26194, 9)\n","Total number of remarks in the compacted categorized file (non-empty cell count): 51458\n","Number of remarks successfully extracted and classified (excluding empty after cleaning): 51459\n","Mismatch: 1 remarks missing from final file count. Investigate Excel saving/loading or if some cells are truly empty/NaN in source.\n","\n","--- Supervised ML Categorization Pipeline Completed in 27.13 seconds ---\n"]}]},{"cell_type":"markdown","source":["<h1>Others Column Reallocation with GEMINI</h1>"],"metadata":{"id":"5ygArxZKl0Il"}},{"cell_type":"code","source":["import os\n","import time\n","import pandas as pd\n","import google.generativeai as genai\n","from joblib import Parallel, delayed\n","import cudf\n","\n","# --- Constants ---\n","API_KEY = \"AIzaSyBHwfAgTs-RzC7uF4QzUSA30_HfMR9MwZQ\"\n","GEMINI_MODEL_NAME = 'gemini-2.5-pro'\n","MAX_RETRIES = 3\n","INITIAL_DELAY_SECONDS = 2\n","BATCH_SIZE = 100\n","MIN_REMARKS_FOR_NEW_COLUMN_SUGGESTION = 3\n","# MAX_REMARKS_FOR_NEW_COLUMN_SUGGESTION = 2000 # No longer directly limiting for the prompt, but be aware of total token limits!\n","\n","# --- Gemini API Configuration ---\n","def configure_gemini_model():\n","    try:\n","        genai.configure(api_key=API_KEY)\n","        return genai.GenerativeModel(GEMINI_MODEL_NAME)\n","    except Exception as e:\n","        print(f\"Error configuring Gemini API: {e}\")\n","        raise\n","\n","\n","# --- Load Excel File ---\n","def load_excel_data(file_path):\n","    try:\n","        df = pd.read_excel(file_path)\n","        return cudf.DataFrame.from_pandas(df)\n","    except Exception as e:\n","        print(f\"Error loading Excel file from '{file_path}': {e}\")\n","        raise\n","\n","\n","# --- Call Gemini with Retry ---\n","def call_gemini_with_retries(prompt, model, task_description=\"processing\", max_retries=MAX_RETRIES, initial_delay=INITIAL_DELAY_SECONDS):\n","    for attempt in range(max_retries):\n","        try:\n","            response = model.generate_content(prompt)\n","            if response and response.text:\n","                return response.text.strip()\n","            else:\n","                raise ValueError(f\"Gemini returned empty or no text during {task_description}.\")\n","        except (ConnectionResetError, genai.types.BlockedPromptException, genai.types.StopCandidateException) as e:\n","            delay = initial_delay * (2 ** attempt)\n","            print(f\"Error (attempt {attempt + 1}) during {task_description}: {e}. Retrying in {delay:.2f} seconds...\")\n","            time.sleep(delay)\n","        except Exception as e:\n","            print(f\"Unexpected error (attempt {attempt + 1}) during {task_description}: {e}.\")\n","            raise\n","    print(f\"Failed to complete {task_description} after {max_retries} attempts.\")\n","    return None\n","\n","\n","# --- Categorize a Single Remark ---\n","def categorize_remark(remark, columns, model):\n","    if not isinstance(remark, str):\n","        return None\n","\n","    prompt = f\"\"\"\n","    Categorize the following remark into **one and only one** of the provided columns. The categorization must be an **exact, clear, unambiguous, and semantic match**.\n","    This means the remark's core meaning and intent must align perfectly with the established definition and typical content of a single column.\n","    **Do not infer, generalize, or make exceptions.** This is a data set of remarks RELATED TO SUPPLY (Like problem with Tranformers, Phase,\n","    Pole, power cut etc), so make sure that the remarks which are categorized IN SOME WAY OR ANOTHER ARE RELATED TO SUPPLY, it should not be the case\n","    that the remarks which are not of supply (example : meter related or bill related remarks) are categorized in one of the provided columns, for such\n","    remarks return 'None'. If the remark does not precisely and directly fit *one specific column* without any doubt,\n","    or if it could arguably fit more than one, return 'None'.\n","    **Columns:** {', '.join(columns)}\n","    **Remark:** {remark.strip()}\n","    Return only the column name or 'None'.\n","    \"\"\"\n","    task_desc = f\"categorizing remark '{remark[:50]}...'\"\n","    return call_gemini_with_retries(prompt, model, task_desc)\n","\n","\n","# --- Suggest New Columns from Uncategorized Remarks ---\n","def suggest_new_columns(uncategorized_remarks, model):\n","    if not uncategorized_remarks:\n","        return {}\n","\n","    # Modification: Send all remarks for suggestion (within reasonable prompt limits)\n","    # Be aware: If 'uncategorized_remarks' is very large, this can exceed token limits.\n","    # It's generally better to sample or batch here if remark count is high.\n","    remarks_for_prompt = [r[:100].strip() for r in uncategorized_remarks] # Still truncate individual remarks to save tokens within the overall prompt\n","\n","    if len(remarks_for_prompt) < MIN_REMARKS_FOR_NEW_COLUMN_SUGGESTION:\n","        return {}\n","\n","    prompt = f\"\"\"\n","    Analyze the following uncategorized remarks that did not fit into existing columns.\n","    Suggest new column names that effectively group similar issues present in these remarks.\n","    Each suggested column must clearly apply to at least {MIN_REMARKS_FOR_NEW_COLUMN_SUGGESTION} of the provided remarks.\n","    For each column, provide:\n","    - Column name (concise and descriptive)\n","    - Brief description of the types of issues it covers\n","    - Estimated number of remarks from the provided list that would fit this new column\n","\n","    Remarks:\\n{chr(10).join(remarks_for_prompt)}\n","\n","    Format exactly as follows:\n","    Column: [Column Name], Description: [Description], Estimated Count: [Count]\n","    If no columns can be clearly identified that meet the minimum threshold, return 'No suggestions'.\n","    \"\"\"\n","    task_desc = \"suggesting new columns\"\n","    response_text = call_gemini_with_retries(prompt, model, task_desc)\n","\n","    new_columns = {}\n","    if response_text and response_text.lower() != 'no suggestions':\n","        for line in response_text.split('\\n'):\n","            line = line.strip()\n","            if line.startswith('Column:'):\n","                try:\n","                    parts = line.split(', Description:')\n","                    column_name = parts[0].replace('Column:', '').strip()\n","                    desc_parts = parts[1].split(', Estimated Count:')\n","                    description = desc_parts[0].strip()\n","                    count = int(desc_parts[1].strip())\n","                    if count >= MIN_REMARKS_FOR_NEW_COLUMN_SUGGESTION:\n","                        new_columns[column_name] = {'description': description, 'count': count}\n","                except (IndexError, ValueError) as e:\n","                    print(f\"Warning: Could not parse suggested column line: '{line}'. Error: {e}\")\n","    return new_columns\n","\n","\n","# --- Process Remarks ---\n","def process_remarks_and_suggest_columns(input_file_path, output_file_path):\n","    df_cudf = load_excel_data(input_file_path)\n","\n","    if 'Others' not in df_cudf.columns:\n","        print(\"Error: 'Others' column not found in the Excel sheet.\")\n","        return\n","\n","    df_pd = df_cudf.to_pandas()\n","\n","    model = configure_gemini_model()\n","    existing_columns = [col for col in df_pd.columns if col != 'Others']\n","\n","    total_rows = len(df_pd)\n","    print(f\"Starting remark categorization for {total_rows} rows...\")\n","\n","    for start_idx in range(0, total_rows, BATCH_SIZE):\n","        end_idx = min(start_idx + BATCH_SIZE, total_rows)\n","        print(f\"Processing batch: rows {start_idx + 1} to {end_idx}...\")\n","\n","        batch_remarks_data = df_pd.loc[start_idx:end_idx-1, ['Others']].dropna()\n","\n","        if batch_remarks_data.empty:\n","            continue\n","\n","        remarks_to_categorize = [\n","            (idx, str(remark)) for idx, remark in batch_remarks_data['Others'].items()\n","        ]\n","\n","        results = Parallel(n_jobs=8)(\n","            delayed(categorize_remark)(remark, existing_columns, model)\n","            for _, remark in remarks_to_categorize\n","        )\n","\n","        for (global_index, original_remark), target_column in zip(remarks_to_categorize, results):\n","            if target_column in existing_columns:\n","                df_pd.at[global_index, target_column] = original_remark\n","                df_pd.at[global_index, 'Others'] = None\n","            # else: the remark implicitly stays in 'Others'\n","\n","    print(\"\\n--- Categorization Complete ---\")\n","\n","    uncategorized_remarks_list = df_pd['Others'].dropna().tolist()\n","\n","    print(f\"\\nSuggesting new columns for {len(uncategorized_remarks_list)} uncategorized remarks...\")\n","    suggested_new_columns = suggest_new_columns(uncategorized_remarks_list, model)\n","\n","    try:\n","        df_pd.to_excel(output_file_path, index=False)\n","        print(f\"Saved updated Excel to: {output_file_path}\")\n","    except Exception as e:\n","        print(f\"Error saving output file: {e}\")\n","\n","    if suggested_new_columns:\n","        print(\"\\n--- Suggested New Columns ---\")\n","        for col, info in suggested_new_columns.items():\n","            print(f\"Column: **{col}**\\n  Description: {info['description']}\\n  Count: {info['count']}\\n\")\n","    else:\n","        print(f\"\\nNo new columns suggested (threshold: {MIN_REMARKS_FOR_NEW_COLUMN_SUGGESTION} remarks).\")\n","\n","    print(f\"\\nTotal remaining uncategorized remarks in 'Others' column: {len(uncategorized_remarks_list)}\")\n","\n","\n","# --- Main ---\n","def main():\n","    input_excel_file = '/content/categorized_remarks_final.xlsx'\n","    output_excel_file = './output.xlsx'\n","\n","    if not os.path.exists(input_excel_file):\n","        print(f\"Input file not found: {input_excel_file}\")\n","        return\n","\n","    process_remarks_and_suggest_columns(input_excel_file, output_excel_file)\n","\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"collapsed":true,"id":"cN8CK82tlyVk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Others Reallocation without GEMINI**"],"metadata":{"id":"E5_nV7FiV-l0"}},{"cell_type":"code","source":["import os\n","import time\n","import pandas as pd\n","import joblib\n","import numpy as np\n","import re\n","import nltk\n","from nltk.corpus import stopwords as nltk_stopwords\n","from sentence_transformers import SentenceTransformer\n","from sklearn.preprocessing import StandardScaler\n","import torch\n","from collections import defaultdict\n","\n","# --- NLTK Setup ---\n","try:\n","    nltk.data.find('corpora/stopwords')\n","except LookupError:\n","    nltk.download('stopwords')\n","\n","UNIVERSAL_STOPWORDS = set(nltk_stopwords.words('english') + [\n","    'the', 'area', 'a', 'an', 'and', 'or', 'but', 'is', 'are', 'was', 'were', 'to', 'of', 'in', 'for', 'on', 'with', 'at', 'from', 'by', 'this', 'that', 'it', 'its', 'her', 'their', 'our',\n","    'what', 'where', 'how', 'why', 'who', 'whom', 'which', 'whether',\n","    'yesterday', 'today', 'tomorrow', 'morning', 'evening', 'night', 'day', 'days', 'hr', 'hrs', 'hour', 'hours', 'time', 'date', 'week', 'month', 'year', 'ago',\n","    'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'zero',\n","    'consumer', 'customer', 'number', 'no', 'code', 'id', 'location', 'address', 'phone', 'mobile', 'call', 'report', 'registered',\n","    'ok', 'yes', 'no', 'not', 'hi', 'hello', 'sir', 'madam', 'pls', 'please', 'regards', 'type', 'urban', 'complaint', 'detail', 'general',\n","    'kv', 'tf', 'na', 'service', 'request', 'feedback', 'query', 'regarding', 'about', 'given', 'areas', 'village'\n","])\n","\n","def clean_text(text: str) -> str:\n","    if pd.isna(text):\n","        return \"\"\n","    text = str(text)\n","    text = re.sub(r'[^a-zA-Z0-9\\s.,!?\\'\"-/]', '', text)\n","    text = re.sub(r'\\s+', ' ', text.strip()).lower()\n","    return text\n","\n","def extract_time_features(remarks_series: pd.Series) -> pd.DataFrame:\n","    remarks_series = remarks_series.fillna(\"\").str.lower()\n","\n","    hour_pattern = r'(\\d+\\.?\\d*)\\s*(?:hr|hrs|hour|hours|h)'\n","    day_pattern = r'(\\d+\\.?\\d*)\\s*(?:day|days)'\n","    am_pm_pattern = r'\\b(\\d{1,2}(:\\d{2})?)\\s*(am|pm)\\b'\n","\n","    hours_extracted = remarks_series.str.extract(hour_pattern)[0].astype(float).fillna(0)\n","    days_extracted = remarks_series.str.extract(day_pattern)[0].astype(float).fillna(0)\n","\n","    hours_from_days = days_extracted * 24\n","    combined_hours = hours_extracted + hours_from_days\n","\n","    is_am_pm_mentioned = remarks_series.str.contains(am_pm_pattern, regex=True).astype(int)\n","\n","    return pd.DataFrame({\n","        'extracted_hours': combined_hours,\n","        'is_am_pm_mentioned': is_am_pm_mentioned\n","    })\n","\n","\n","def classify_others_column_using_pretrained_model(input_file_path, output_file_path): # Added parameters here\n","    # Model paths from your 'Supply Code' project\n","    SENTENCE_TRANSFORMER_MODEL_PATH = 'sentence_transformer_model.pkl'\n","    CLASSIFIER_MODEL_PATH = 'logistic_regression_classifier.pkl'\n","    SCALER_MODEL_PATH = 'scaler_for_time_features.pkl'\n","\n","    # Configuration for this specific task\n","    input_others_excel_path = input_file_path # Use the passed parameter\n","    output_classified_excel_path = output_file_path # Use the passed parameter\n","    SOURCE_COLUMN_TO_CLASSIFY = \"Others\"\n","    CONFIDENCE_THRESHOLD = 0.7\n","\n","    # Target category labels for classification\n","    # for supply\n","    TARGET_CATEGORY_LABELS = [\n","        \"Less than 4 hours\", \"More than 12 hours\", \"More than 24 hours\", \"More than 4 hours\",\n","        \"Consumer Power Supply Failures\", \"Failed Pole Incident Category\", \"Other Language Remarks\",\n","        \"Partial Phase Supply Failure\", \"Transformer Damage Causing Outages\"\n","    ]\n","\n","    \"\"\"\n","    TARGET_CATEGORY_LABELS = [ # for billing\n","        \"Bill Accuracy and Discrepancies\", \"Bill Content and Delivery Discrepancies\", \"Other Language Remarks\",\n","        \"Bill Hold Preventing Online Payments\", \"Billing Discrepancies Due to Meter Readings\", \"Domestic Connection Billing Discrepancies\",\n","        \"Customer Billing Not Received or Available\"\n","    ]\n","    \"\"\"\n","\n","    print(\"--- Starting ML-based Classification of 'Others' Column ---\")\n","    start_time = time.time()\n","\n","    # --- 1. Load Pre-trained Models ---\n","    print(\"\\n--- 1. Loading Pre-trained Models ---\")\n","    try:\n","        model_embedding = joblib.load(SENTENCE_TRANSFORMER_MODEL_PATH)\n","        classifier_model = joblib.load(CLASSIFIER_MODEL_PATH)\n","        scaler = joblib.load(SCALER_MODEL_PATH)\n","        print(\"Models loaded successfully.\")\n","\n","        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","        model_embedding.to(torch.device(device))\n","        print(f\"SentenceTransformer model moved to device: {device}\")\n","\n","    except FileNotFoundError as e:\n","        print(f\"ERROR: Model file not found: {e}. Ensure .pkl files are in the directory from running 'Supply Code' script.\")\n","        return\n","    except Exception as e:\n","        print(f\"ERROR in loading models: {e}\")\n","        import traceback; traceback.print_exc()\n","        return\n","\n","    # --- 2. Load Input Data and Extract Remarks from 'Others' Column ---\n","    print(f\"\\n--- 2. Loading input data from '{input_others_excel_path}' ---\")\n","    try:\n","        df_input_raw = pd.read_excel(input_others_excel_path)\n","        print(f\"Loaded '{input_others_excel_path}'. Shape: {df_input_raw.shape}\")\n","\n","        if SOURCE_COLUMN_TO_CLASSIFY not in df_input_raw.columns:\n","            print(f\"ERROR: Column '{SOURCE_COLUMN_TO_CLASSIFY}' not found in '{input_others_excel_path}'. Available: {df_input_raw.columns.tolist()}\")\n","            return\n","\n","        remarks_to_process = []\n","        for idx, remark_raw in df_input_raw[SOURCE_COLUMN_TO_CLASSIFY].items():\n","            cleaned_remark = clean_text(remark_raw)\n","            if cleaned_remark:\n","                remarks_to_process.append({\n","                    'original_index': idx,\n","                    'remark_raw': remark_raw,\n","                    'remark_cleaned': cleaned_remark\n","                })\n","\n","        df_remarks_for_ml = pd.DataFrame(remarks_to_process)\n","        print(f\"Extracted {len(df_remarks_for_ml)} valid remarks from '{SOURCE_COLUMN_TO_CLASSIFY}' for classification.\")\n","\n","        if df_remarks_for_ml.empty:\n","            print(f\"No valid remarks found in '{SOURCE_COLUMN_TO_CLASSIFY}'. Skipping classification. Output file will be original data.\")\n","            df_input_raw.to_excel(output_file_path, index=False)\n","            print(\"--- ML-based Classification Completed (No remarks to classify) ---\")\n","            return\n","\n","    except FileNotFoundError:\n","        print(f\"ERROR: Input file '{input_others_excel_path}' not found.\")\n","        return\n","    except Exception as e:\n","        print(f\"ERROR in loading input data: {e}\")\n","        import traceback; traceback.print_exc()\n","        return\n","\n","    # --- 3. Generate Features and Predict Categories ---\n","    print(\"\\n--- 3. Generating Features and Predicting Categories ---\")\n","    try:\n","        print(\"Generating embeddings for remarks...\")\n","        embeddings = model_embedding.encode(\n","            df_remarks_for_ml['remark_cleaned'].tolist(), show_progress_bar=True, convert_to_numpy=True\n","        )\n","\n","        print(\"Extracting and scaling time features...\")\n","        time_features_df = extract_time_features(df_remarks_for_ml['remark_cleaned'])\n","        scaled_time_features = scaler.transform(time_features_df)\n","\n","        combined_features = np.hstack((embeddings, scaled_time_features))\n","\n","        print(f\"Predicting probabilities with threshold={CONFIDENCE_THRESHOLD}...\")\n","        prediction_probabilities = classifier_model.predict_proba(combined_features)\n","\n","        predicted_class_indices = np.argmax(prediction_probabilities, axis=1)\n","        predicted_labels = classifier_model.classes_[predicted_class_indices]\n","        max_probabilities = np.max(prediction_probabilities, axis=1)\n","\n","        df_remarks_for_ml['predicted_label'] = predicted_labels\n","        df_remarks_for_ml['confidence'] = max_probabilities\n","\n","    except Exception as e:\n","        print(f\"ERROR in feature generation or prediction: {e}\")\n","        import traceback; traceback.print_exc()\n","        return\n","\n","    # --- 4. Distribute Remarks and Structure Output ---\n","    print(\"\\n--- 4. Distributing Remarks and Structuring Output ---\")\n","\n","    df_output = df_input_raw.copy()\n","\n","    if SOURCE_COLUMN_TO_CLASSIFY in df_output.columns:\n","        df_output[SOURCE_COLUMN_TO_CLASSIFY] = None\n","\n","    classified_count = 0\n","    retained_in_others_count = 0\n","\n","    for i, row_data in df_remarks_for_ml.iterrows():\n","        original_idx = row_data['original_index']\n","        remark_raw = row_data['remark_raw']\n","        predicted_label = row_data['predicted_label']\n","        confidence = row_data['confidence']\n","\n","        if confidence >= CONFIDENCE_THRESHOLD:\n","            df_output.at[original_idx, predicted_label] = remark_raw\n","            classified_count += 1\n","        else:\n","            df_output.at[original_idx, SOURCE_COLUMN_TO_CLASSIFY] = remark_raw\n","            retained_in_others_count += 1\n","\n","    print(f\"Reclassified {classified_count} remarks from '{SOURCE_COLUMN_TO_CLASSIFY}' into specific categories.\")\n","    print(f\"Retained {retained_in_others_count} remarks in '{SOURCE_COLUMN_TO_CLASSIFY}' due to low confidence.\")\n","\n","    # --- Final Output Formatting (Compacted) ---\n","    final_compacted_data = defaultdict(list)\n","    all_output_cols = sorted(list(set(TARGET_CATEGORY_LABELS) | set([SOURCE_COLUMN_TO_CLASSIFY])))\n","\n","    for col in df_output.columns:\n","        if col in all_output_cols:\n","            for remark_entry in df_output[col].dropna():\n","                if str(remark_entry).strip():\n","                    final_compacted_data[col].append(remark_entry)\n","\n","    max_rows_final_output = 0\n","    if final_compacted_data:\n","        max_rows_final_output = max(len(v) for v in final_compacted_data.values())\n","\n","    df_final_output_compacted = pd.DataFrame({\n","        col: final_compacted_data.get(col, []) + [''] * (max_rows_final_output - len(final_compacted_data.get(col, [])))\n","        for col in all_output_cols\n","    })\n","\n","\n","    print(f\"\\nFinal Compacted Output DataFrame shape: {df_final_output_compacted.shape}\")\n","    print(\"First 5 rows of the Final Compacted Output DataFrame:\")\n","    print(df_final_output_compacted.head())\n","\n","    # --- 5. Save Results ---\n","    print(f\"\\n--- 5. Saving results to '{output_file_path}' ---\")\n","    try:\n","        df_final_output_compacted.to_excel(output_file_path, index=False)\n","        print(\"Results saved successfully.\")\n","    except Exception as e:\n","        print(f\"ERROR saving output file: {e}\")\n","        import traceback; traceback.print_exc()\n","\n","    print(f\"\\n--- ML-based Classification of 'Others' Column Completed in {time.time() - start_time:.2f} seconds ---\")\n","\n","\n","# --- Main execution block ---\n","if __name__ == \"__main__\":\n","\n","    input_file_for_others = './categorized_remarks_final.xlsx' # Input path for this script\n","    output_file_after_others_classification = './output_others_classified.xlsx' # Output path for this script\n","\n","    if not os.path.exists(input_file_for_others):\n","        print(f\"ERROR: Input file not found: {input_file_for_others}. Ensure it exists and has the 'Others' column.\")\n","    else:\n","        classify_others_column_using_pretrained_model(input_file_for_others, output_file_after_others_classification)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f1f2d1a49aa14df6983b41a9e3b8b5cc","ae0fc34f07c34e35bb8e5ba3015c9829","c7855580a53f480d84599265e795349d","bb46e500f44c4dc392ad921eec844515","a3dfc2abc2b74a3eb9bdeaf46eeade0f","0164fdadeae84d58aa5fa0b9b896374a","aefcafa4a48f41d9926c3293f50323dd","297d6dc135204a588bd21f508a3605cb","b59d5b09d96c44e98f5d357c084671ab","b74cf98286dc402ab908ccd71c6284cf","0b8d3c4bafd34bb5967c3274793c551d"]},"collapsed":true,"id":"B7-Ugdl5PY_t","executionInfo":{"status":"ok","timestamp":1753693334478,"user_tz":-330,"elapsed":25080,"user":{"displayName":"Aadi","userId":"17429767985240166296"}},"outputId":"373ccd49-a77c-4295-e550-d2b307659c0a"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Starting ML-based Classification of 'Others' Column ---\n","\n","--- 1. Loading Pre-trained Models ---\n","Models loaded successfully.\n","SentenceTransformer model moved to device: cuda\n","\n","--- 2. Loading input data from './categorized_remarks_final.xlsx' ---\n","Loaded './categorized_remarks_final.xlsx'. Shape: (76080, 11)\n","Extracted 333 valid remarks from 'Others' for classification.\n","\n","--- 3. Generating Features and Predicting Categories ---\n","Generating embeddings for remarks...\n"]},{"output_type":"display_data","data":{"text/plain":["Batches:   0%|          | 0/11 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1f2d1a49aa14df6983b41a9e3b8b5cc"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting and scaling time features...\n","Predicting probabilities with threshold=0.7...\n","\n","--- 4. Distributing Remarks and Structuring Output ---\n","Reclassified 122 remarks from 'Others' into specific categories.\n","Retained 211 remarks in 'Others' due to low confidence.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n","  return forward_call(*args, **kwargs)\n","/tmp/ipython-input-18-3506448307.py:51: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n","  is_am_pm_mentioned = remarks_series.str.contains(am_pm_pattern, regex=True).astype(int)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Final Compacted Output DataFrame shape: (76079, 10)\n","First 5 rows of the Final Compacted Output DataFrame:\n","                      Consumer Power Supply Failures  \\\n","0    \\t\\t\\t\\t\\nConsumer Problem-Supply Failed In ...   \n","1    \\t\\t\\t\\t\\nConsumer Problem-Supply Failed In ...   \n","2    \\t\\t\\nConsumer Problem- Supply Failed In His...   \n","3    \\nConsumer Problem-Supply Failed In His  Hou...   \n","4   \\t\\t\\t\\t\\nConsumer Problem-Supply Failed In H...   \n","\n","                       Failed Pole Incident Category  \\\n","0                      Cable disconnected from pole.   \n","1  Current is not coming in meter from electricit...   \n","2                                   Loose from  pole   \n","3                                   Loose from pole    \n","4                                   Loose from pole    \n","\n","                                   Less than 4 hours  \\\n","0    \\t\\t\\t\\t\\nConsumer Problem-Supply Failed In ...   \n","1    \\t\\t\\nConsumer Problem- Supply Failed In His...   \n","2   \\t\\t\\t\\t\\nConsumer Problem-Supply Failed In H...   \n","3   \\t\\t\\t\\t\\nConsumer Problem-Supply Failed In H...   \n","4   Consumer Problem - SUPPLY FAILED  in his vill...   \n","\n","                                  More than 12 hours  \\\n","0   \\nConsumer Problem-Supply Failed In His 20 ho...   \n","1   Consumer Problem - Supply Failed In His  20 H...   \n","2  \\t\\t\\t\\t\\nConsumer Problem- Supply Failed In H...   \n","3  \\t\\t\\t\\t\\nConsumer Problem- Supply Failed In H...   \n","4  \\t\\t\\t\\t\\nConsumer Problem-Supply Failed In Hi...   \n","\n","                                  More than 24 hours  \\\n","0     \\t\\t\\t\\t\\nConsumer Problem-Supply Failed In...   \n","1    \\t\\t\\nConsumer Problem- Supply Failed In His...   \n","2    \\t\\n  VILL Transformer damage from last- 5 D...   \n","3    PTW-  Transformer Damage From Last - 20  day...   \n","4    VILL Transformer damage from last- 2 DAYS   ...   \n","\n","                                   More than 4 hours  \\\n","0    \\t\\t\\t\\t\\nConsumer Problem-Supply Failed In ...   \n","1    \\t\\t\\t\\t\\nConsumer Problem-Supply Failed In ...   \n","2    \\t\\t\\t\\t\\nConsumer Problem-Supply Failed In ...   \n","3    \\nConsumer Problem-Supply Failed In His  4 h...   \n","4   \\t\\t\\t \\t\\t\\t\\t\\nCONSUMER PROBLEM- SUPPLY FAI...   \n","\n","                              Other Language Remarks  \\\n","0                                     fault in pole    \n","1                                      pole se khrab   \n","2  \\tDV01072505347...................... pending\\n\\n   \n","3                                 1 phase ni aa rha    \n","4                                  11 kva line fault   \n","\n","                                              Others  \\\n","0    \\t\\t\\t\\t\\nConsumer Problem-Supply Failed In ...   \n","1    \\t\\t\\t\\t\\nConsumer Problem-Supply Failed In ...   \n","2    \\t\\t\\nConsumer Problem- Supply Failed In His...   \n","3    \\t\\t\\nConsumer Problem- Supply Failed In His...   \n","4    \\nConsumer Problem-Supply Failed In His  4 h...   \n","\n","                        Partial Phase Supply Failure  \\\n","0  2 PHASE NOT COMING AT BSNL BARUASAGAR TELEPHON...   \n","1  Low voltage in one phase thats why solar plant...   \n","2                                 one phase not come   \n","3  My area light mostly missing most of time some...   \n","4  2 PHASE NOT COMING AT BSNL BARUASAGAR TELEPHON...   \n","\n","                  Transformer Damage Causing Outages  \n","0   PTW  Transformer damage from last days -\\t1 w...  \n","1   PTW Transformer damage from last days - 1 mon...  \n","2   PTW Transformer Damage From Last-1 MONTH \\t\\t...  \n","3   VILL - tf damage from last\\t- Today Morning \\...  \n","4   VILL  Transformer damage from last days -\\t1 ...  \n","\n","--- 5. Saving results to './output_others_classified.xlsx' ---\n","Results saved successfully.\n","\n","--- ML-based Classification of 'Others' Column Completed in 25.01 seconds ---\n"]}]},{"cell_type":"code","source":["!pip freeze > requirements.txt"],"metadata":{"id":"f0dCuukkY1Ex","executionInfo":{"status":"ok","timestamp":1753693102666,"user_tz":-330,"elapsed":1232,"user":{"displayName":"Aadi","userId":"17429767985240166296"}}},"execution_count":16,"outputs":[]}],"metadata":{"colab":{"gpuType":"A100","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyNOIbS3kfyZNC56FReMATZl"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"62dd843fb86a4c81bc45de16836b9ab0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_86922d8602a34e55b544569148fad9d3","IPY_MODEL_7959bb4c43c942cd869c1643922bf7a1","IPY_MODEL_fa0589f2159642e8b634d51db1f1dda7"],"layout":"IPY_MODEL_cf9a066b5ddc4664909a310e008b8892"}},"86922d8602a34e55b544569148fad9d3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b99560b984e14f67944d517d62adb21a","placeholder":"​","style":"IPY_MODEL_8b5b323640934a1ba65f15ca9ba29257","value":"Batches: 100%"}},"7959bb4c43c942cd869c1643922bf7a1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_caeba5d28864423b9c140dc43e874abf","max":51,"min":0,"orientation":"horizontal","style":"IPY_MODEL_abb7cff50e724749a1a1d1a3cac27378","value":51}},"fa0589f2159642e8b634d51db1f1dda7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e8c72625a684771956b191e5f8dc6c4","placeholder":"​","style":"IPY_MODEL_69d76ab0e50349f68844ba28d47788ef","value":" 51/51 [00:00&lt;00:00, 121.19it/s]"}},"cf9a066b5ddc4664909a310e008b8892":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b99560b984e14f67944d517d62adb21a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b5b323640934a1ba65f15ca9ba29257":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"caeba5d28864423b9c140dc43e874abf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abb7cff50e724749a1a1d1a3cac27378":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9e8c72625a684771956b191e5f8dc6c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69d76ab0e50349f68844ba28d47788ef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"71ff0a74c0fd4460a7c3932acb8dee74":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b848296d63c547dfbe2a627aec4c3283","IPY_MODEL_9e18358527204739b1dcd7cc5d21ae60","IPY_MODEL_be3b3f2807964974bff8acf1b07e67ac"],"layout":"IPY_MODEL_cbb902550e224987a17480aa465ace8c"}},"b848296d63c547dfbe2a627aec4c3283":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_31a7932b34864ae09e589fe1adf249be","placeholder":"​","style":"IPY_MODEL_bbc99a0c4520491eb460a4a50b908e3d","value":"Batches: 100%"}},"9e18358527204739b1dcd7cc5d21ae60":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_172b25e57daa481f962c90929b49587a","max":13,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b9397583369646619be29c53db9832ea","value":13}},"be3b3f2807964974bff8acf1b07e67ac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7114a91d1cfd4356943032c31e9fe774","placeholder":"​","style":"IPY_MODEL_5d5de136e3aa4ffe97ff46a3db93bde5","value":" 13/13 [00:00&lt;00:00, 113.53it/s]"}},"cbb902550e224987a17480aa465ace8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31a7932b34864ae09e589fe1adf249be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bbc99a0c4520491eb460a4a50b908e3d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"172b25e57daa481f962c90929b49587a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9397583369646619be29c53db9832ea":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7114a91d1cfd4356943032c31e9fe774":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d5de136e3aa4ffe97ff46a3db93bde5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"84c2601bc596458aba030b9d61fe38e2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0b82a6590acb493abd0921c5452c59a7","IPY_MODEL_9e4dd6a0aced466890bc71b6ec868173","IPY_MODEL_2da131e79fe24b4cadb0ff887c644aa2"],"layout":"IPY_MODEL_e4a09bae9bad46afbf7d29646bbe2b74"}},"0b82a6590acb493abd0921c5452c59a7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_56fba1f5cf8b4b83939edc2a0fea3a52","placeholder":"​","style":"IPY_MODEL_96cc2991268f489f8d49d5f62cf88462","value":"Batches: 100%"}},"9e4dd6a0aced466890bc71b6ec868173":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7d852bad16d48d4b5848f63a586098b","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d01453946dc14f5e9557fff426809ad4","value":50}},"2da131e79fe24b4cadb0ff887c644aa2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a41f977b02d4236a3db134d95720337","placeholder":"​","style":"IPY_MODEL_8579b4ab27e14762b9098ef89367657f","value":" 50/50 [00:00&lt;00:00, 135.62it/s]"}},"e4a09bae9bad46afbf7d29646bbe2b74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56fba1f5cf8b4b83939edc2a0fea3a52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96cc2991268f489f8d49d5f62cf88462":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e7d852bad16d48d4b5848f63a586098b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d01453946dc14f5e9557fff426809ad4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0a41f977b02d4236a3db134d95720337":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8579b4ab27e14762b9098ef89367657f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8f3933d8d08b4fcfba52cd3b1710a5e6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d1e5835018494fa08ef1064447969ea5","IPY_MODEL_d5b1b9d68f3e4c3fb6447292cf8f45f5","IPY_MODEL_f7e34a44692a416fa8c4d40970a56d6c"],"layout":"IPY_MODEL_b1dc78079f6d4fc882d8240cfabe7642"}},"d1e5835018494fa08ef1064447969ea5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0efffcd2c614c2daeb50e2750c140a2","placeholder":"​","style":"IPY_MODEL_2c04fb391a1f4363a7d8feb931353de9","value":"Batches: 100%"}},"d5b1b9d68f3e4c3fb6447292cf8f45f5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b84bfe97008a4b45974f345cbf65ca3e","max":13,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5f2d958834c145adbc784ff601bf87d1","value":13}},"f7e34a44692a416fa8c4d40970a56d6c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac289169fa3046e0b09da28b74c85ecf","placeholder":"​","style":"IPY_MODEL_6e9cb103f529413d9229b11347c661e6","value":" 13/13 [00:00&lt;00:00, 116.37it/s]"}},"b1dc78079f6d4fc882d8240cfabe7642":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0efffcd2c614c2daeb50e2750c140a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c04fb391a1f4363a7d8feb931353de9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b84bfe97008a4b45974f345cbf65ca3e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f2d958834c145adbc784ff601bf87d1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ac289169fa3046e0b09da28b74c85ecf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e9cb103f529413d9229b11347c661e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4dc8d26d1e3344178ffbfb8525cf7485":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_02ec20c9164d48fe8d5b88a684178316","IPY_MODEL_6394b4ccf4314c32b4fdd590d7017f09","IPY_MODEL_d809d2ad634f499aaefe56db1cc3c806"],"layout":"IPY_MODEL_102cc5fde9df4cb5aee8b14d8adba700"}},"02ec20c9164d48fe8d5b88a684178316":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_01bdb2a3bbd342008276be470f18698a","placeholder":"​","style":"IPY_MODEL_c6f7b9856acd43c0b2272015b7f456f3","value":"Batches: 100%"}},"6394b4ccf4314c32b4fdd590d7017f09":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1f743936cf44b4eaa55b4c78289a845","max":1609,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4deb89b017134c9b9ae735387139eb99","value":1609}},"d809d2ad634f499aaefe56db1cc3c806":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3302426b02bc4647a15178b0ec5f9501","placeholder":"​","style":"IPY_MODEL_873d1cb52f2c49f892065976366e5483","value":" 1609/1609 [00:11&lt;00:00, 162.01it/s]"}},"102cc5fde9df4cb5aee8b14d8adba700":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01bdb2a3bbd342008276be470f18698a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6f7b9856acd43c0b2272015b7f456f3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b1f743936cf44b4eaa55b4c78289a845":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4deb89b017134c9b9ae735387139eb99":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3302426b02bc4647a15178b0ec5f9501":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"873d1cb52f2c49f892065976366e5483":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f1f2d1a49aa14df6983b41a9e3b8b5cc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ae0fc34f07c34e35bb8e5ba3015c9829","IPY_MODEL_c7855580a53f480d84599265e795349d","IPY_MODEL_bb46e500f44c4dc392ad921eec844515"],"layout":"IPY_MODEL_a3dfc2abc2b74a3eb9bdeaf46eeade0f"}},"ae0fc34f07c34e35bb8e5ba3015c9829":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0164fdadeae84d58aa5fa0b9b896374a","placeholder":"​","style":"IPY_MODEL_aefcafa4a48f41d9926c3293f50323dd","value":"Batches: 100%"}},"c7855580a53f480d84599265e795349d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_297d6dc135204a588bd21f508a3605cb","max":11,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b59d5b09d96c44e98f5d357c084671ab","value":11}},"bb46e500f44c4dc392ad921eec844515":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b74cf98286dc402ab908ccd71c6284cf","placeholder":"​","style":"IPY_MODEL_0b8d3c4bafd34bb5967c3274793c551d","value":" 11/11 [00:00&lt;00:00, 104.90it/s]"}},"a3dfc2abc2b74a3eb9bdeaf46eeade0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0164fdadeae84d58aa5fa0b9b896374a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aefcafa4a48f41d9926c3293f50323dd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"297d6dc135204a588bd21f508a3605cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b59d5b09d96c44e98f5d357c084671ab":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b74cf98286dc402ab908ccd71c6284cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b8d3c4bafd34bb5967c3274793c551d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}